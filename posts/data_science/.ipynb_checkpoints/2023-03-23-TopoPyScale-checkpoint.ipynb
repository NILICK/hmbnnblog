{
 "cells": [
  {
   "cell_type": "raw",
   "id": "898144f1-fac6-4ba6-8d5f-c28d64fe15e9",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"TopoPyScale\"\n",
    "description: \"Downscaling climate data based on topography.\"\n",
    "author: \"Me\"\n",
    "date: \"2023-03-23\"\n",
    "categories: [GeoSpatial, Downscale, Climate]\n",
    "image: images/downscale.jpeg\n",
    "skip_exec: true\n",
    "skip_showdoc: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218e1a77-2f19-4815-ac7f-a87b7be4b9c9",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "__TopoPyScale__ is a downscaling toolbox for globmal and regional climate model datasets, particularly relevant to mountain ranges, and hillslopes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85750e04-70df-46d7-96f9-8817fa354d37",
   "metadata": {},
   "source": [
    "src: https://topopyscale.readthedocs.io/en/latest/m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b7c7e0-7917-4f8a-8a65-db5748bbd281",
   "metadata": {},
   "source": [
    "`TopoPyScale` uses both climate model data and Digital Elevation Models (DEM) for correcting atmospheric state variables (e.g. temperature, pressure, humidity, etc). TopoPyScale provides tools to interpolate and correct such variables to be relevant locally given a topographical context.\n",
    "\n",
    "The most basic requirements of TopoPyScale is a DEM used to defined the spatial domain of interest as well as compute a number of morphometrics, and configuration file defining the temporal period, the downscaling methods and other parameters. In its current version, `TopoPyScale` includes the `topoclass` class that wraps all functionalities for ease of use. It automatically fetches data from the [ERA5](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-pressure-levels?tab=overview) repositories (Pressure and Surface levels). Other climate data sources can be added. Based on the high resolution (30-100m) DEM and the climate data, methods in the `topoclass` will compute, correct and interpolate variables need to force specialized land-surface models.\n",
    "\n",
    "Indeed, with this library you can download hourly ERA5 climate data and the downscale them in desires spatial resolution.\n",
    "\n",
    "Downscaled variable includes:\n",
    "\n",
    "    2m air temperature\n",
    "    2m air humidity\n",
    "    2m air pressure\n",
    "    10m wind speed and direction\n",
    "    Surface incoming shortwave radiation\n",
    "    Surface incoming longwave radiation\n",
    "    Precipitation (possibility to partition snow and rain)\n",
    "\n",
    "In the following, you can done downscaling climate data step-by-step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1a4b25-b082-48ca-8a92-934c4257bd60",
   "metadata": {},
   "source": [
    "### 1- Python Environment Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def1dcd9-e0db-41df-9c22-b8c0a0304980",
   "metadata": {},
   "source": [
    "TopoPyScale is tested for `Python 3.9`. You may create a new virtual environment using conda prior to installation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57558778-3bdf-4de1-b2c5-906b91015e17",
   "metadata": {},
   "source": [
    "    conda create -n downscaling python=3.9 ipython\n",
    "    conda activate downscaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a4c00-7abd-4d43-a5b9-07b09bb7c059",
   "metadata": {},
   "source": [
    "For install dependencies use `mamba` instead `conda`:\n",
    "\n",
    "    mamba install xarray matplotlib scikit-learn pandas numpy netcdf4 h5netcdf rasterio pyproj dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e860cb-5f1e-4a9b-ad9b-5038a6c20734",
   "metadata": {},
   "source": [
    "### 2- Release Installation\n",
    "\n",
    "    pip install topopyscale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743eff89-7d3a-4b54-9e81-3723fc1e3c8c",
   "metadata": {},
   "source": [
    "### 3- Setting up `cdsapi`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f726af6-1719-482b-bc69-beefe014f337",
   "metadata": {},
   "source": [
    "Then you need to setup your `cdsapi` with the Copernicus API key system. After after creating an account with [Copernicus](https://cds.climate.copernicus.eu/), use following step for setting up to download EAR5 data. \n",
    "\n",
    "#### 3-1- Config File\n",
    "\n",
    "On Linux, create a file gedit `~/.cdsapirc` or ` $HOME/.cdsapirc` with inside:\n",
    "\n",
    "    url: https://cds.climate.copernicus.eu/api/v2\n",
    "    key: 2609:a8a3aba4-af46-4f7a-a79b-5799b58def50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4046513-4bc1-4f36-92e7-8fc67ee49cd3",
   "metadata": {},
   "source": [
    "#### 3-2- Install cdsapi\n",
    "\n",
    "    pip install cdsapi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13206b1f-d356-487f-9998-7bba94eba76f",
   "metadata": {},
   "source": [
    "#### 3-3- Testing download climate data\n",
    "\n",
    "In jupyterlab cell:\n",
    "\n",
    "    import cdsapi\n",
    "    c = cdsapi.Client()\n",
    "    c.retrieve(\"reanalysis-era5-pressure-levels\",\n",
    "    {\n",
    "    \"variable\": \"temperature\",\n",
    "    \"pressure_level\": \"1000\",\n",
    "    \"product_type\": \"reanalysis\",\n",
    "    \"year\": \"2008\",\n",
    "    \"month\": \"01\",\n",
    "    \"day\": \"01\",\n",
    "    \"time\": \"12:00\",\n",
    "    \"format\": \"grib\"\n",
    "    }, \"download.grib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd56536c-52a6-491b-9241-e886d0ba0f34",
   "metadata": {},
   "source": [
    "### 4- Create your project directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15df6b42-6130-42bf-89e4-6ca91082b756",
   "metadata": {},
   "source": [
    "Folders and files in your project directory must be as follow:\n",
    "Note:  `inputs`, `dem` amd `config.yml` files are mandatory\n",
    "\n",
    "    my_project/\n",
    "        ├── inputs/\n",
    "            ├── dem/ \n",
    "                ├── my_dem.tif\n",
    "                └── pts_list.csv  (OPTIONAL: to downscale to specific points)\n",
    "            └── climate/\n",
    "                ├── PLEV*.nc\n",
    "                └── SURF*.nc\n",
    "        ├── outputs/\n",
    "                ├── tmp/\n",
    "        ├── pipeline.py (OPTIONAL: script for the downscaling instructions)\n",
    "        └── config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9a12cc-09e7-480f-b868-92157726beb4",
   "metadata": {},
   "source": [
    "### 5- Create Config file\n",
    "\n",
    "Create `config.yml` file in project directory with inside for example:\n",
    "\n",
    "    project:\n",
    "        name: Khaeiz\n",
    "        description: Downscaling for the Khaeiz mountains\n",
    "        authors:\n",
    "            - Madadi H.\n",
    "        date: March 2023\n",
    "        directory: /mnt/864424144424098F/Anaconda_Projects/Climate_DownScale/Caracal/Topopyscale_prj_khaeiz/\n",
    "        start: 2020-01-01\n",
    "        end: 2020-12-31\n",
    "        split:\n",
    "            IO: False\n",
    "            time: 1  # run indivudal batch in time\n",
    "            space: None  # to be implemented\n",
    "        extent: \n",
    "        CPU_cores: 4\n",
    "        climate: era5\n",
    "\n",
    "    climate:\n",
    "        era5:\n",
    "            path: inputs/climate/\n",
    "            product: reanalysis\n",
    "            timestep: 1H\n",
    "            plevels: [700,750,800,850,900,950,1000]\n",
    "            download_threads: 12\n",
    "\n",
    "    dem:\n",
    "        file: srtm_47_06_z39_khaeiz.tif\n",
    "        epsg: 32639\n",
    "        horizon_increments: 10\n",
    "\n",
    "    sampling:\n",
    "        method: toposub\n",
    "\n",
    "\n",
    "        toposub:\n",
    "            clustering_method: minibatchkmean\n",
    "            n_clusters: 50\n",
    "            random_seed: 2\n",
    "            clustering_features: {'x':1, 'y':1, 'elevation':4, 'slope':1, 'aspect_cos':1, 'aspect_sin':1, 'svf':1}\n",
    "\n",
    "\n",
    "    toposcale:\n",
    "        interpolation_method: idw\n",
    "        pt_sampling_method: nearest\n",
    "        LW_terrain_contribution: True\n",
    "\n",
    "    outputs:\n",
    "        variables: all  # list or combination name\n",
    "        file:\n",
    "            clean_outputs: True\n",
    "            clean_FSM: True\n",
    "            df_centroids: df_centroids.pck\n",
    "            ds_param: ds_param.nc\n",
    "            ds_solar: ds_solar.nc\n",
    "            da_horizon: da_horizon.nc\n",
    "            landform: landform.tif\n",
    "            downscaled_pt: down_pt_*.nc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfcb71b-53e8-4a48-b883-3449f8d00a12",
   "metadata": {},
   "source": [
    "### 6- Run codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe3e77-7675-45a1-bc9c-9e60459f78fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from TopoPyScale import topoclass as tc\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0599c374-ef60-4f5b-baf0-7195a69d1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= STEP 1 ==========\n",
    "# Load Configuration\n",
    "config_file = '/mnt/864424144424098F/Anaconda_Projects/Climate_DownScale/Caracal/Topopyscale_prj_khaeiz/config.yml'\n",
    "mp = tc.Topoclass(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8789a47a-4bb6-45e2-b466-042ce8abe002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== STEP 2 ===========\n",
    "# Compute parameters of the DEM (slope, aspect, sky view factor)\n",
    "mp.compute_dem_param()\n",
    "mp.extract_topo_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc4123a-2b23-4b45-8e56-d02c5a380802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Option 1:\n",
    "# Compute clustering of the input DEM and extract cluster centroids\n",
    "#mp.extract_dem_cluster_param()\n",
    "mp.extract_topo_cluster_param()\n",
    "# plot clusters\n",
    "mp.toposub.plot_clusters_map()\n",
    "# plot sky view factor\n",
    "mp.toposub.plot_clusters_map(var='svf', cmap=plt.cm.viridis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1f1eeb-24d0-4565-bbe5-d52089bc640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= STEP 3 ==========\n",
    "# compute solar geometry and horizon angles\n",
    "mp.compute_solar_geometry()\n",
    "mp.compute_horizon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9960266a-1d1e-46a1-9f79-71b5266c5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= STEP 4 ==========\n",
    "# Perform the downscaling\n",
    "mp.downscale_climate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb8791d-1510-4e3e-948a-f7a78c64229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= STEP 5 ==========\n",
    "# Export output to desired format\n",
    "mp.to_netcdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a692a68c-d022-4fb4-998e-680495fdcff6",
   "metadata": {},
   "source": [
    "### 7- Convert `Hourly` to `Yearly` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4369369-d433-4222-bdcd-dbb1bc9b7537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "ds_down_dsk = xr.open_dataset(\n",
    "    \"./Caracal/Topopyscale_prj_khaeiz/outputs/output.nc\",\n",
    "    chunks={\"point_id\": 10}\n",
    ")\n",
    "ds_down_dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536b3f6f-b55a-4c0d-9d93-59c01b16466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_year = ds_down_dsk.groupby('time.year').mean('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e422c15-d0c3-474d-a030-9fa332252b6d",
   "metadata": {},
   "source": [
    "### 8- Adding Coordinate dimention to results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bee6ece-c933-4eb2-bea3-351af5d4677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_param = xr.open_dataset(\"./Caracal/Topopyscale_prj_khaeiz/outputs/ds_param.nc\")\n",
    "ds_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc5f97e-36ab-4350-9f96-d88cb373749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_khaeiz = ds_year.sel(point_id=ds_param.cluster_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77953ce3-aa0d-45e1-a8a5-762f6a856789",
   "metadata": {},
   "source": [
    "### 9- Saving reult to netcdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e793852c-67f7-40ab-a24f-042763724441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scaling_and_offset(da, n=16):\n",
    "    \"\"\"\n",
    "    Compute offset and scale factor for int conversion\n",
    "\n",
    "    Args:\n",
    "        da (dataarray): of a given variable\n",
    "        n (int): number of digits to account for\n",
    "    \"\"\"\n",
    "    vmin = float(da.min().values)\n",
    "    vmax = float(da.max().values)\n",
    "\n",
    "    # stretch/compress data to the available packed range\n",
    "    scale_factor = (vmax - vmin) / (2 ** n - 1)\n",
    "    # translate the range to be symmetric about zero\n",
    "    add_offset = vmin + 2 ** (n - 1) * scale_factor\n",
    "\n",
    "    return scale_factor, add_offset\n",
    "\n",
    "def to_netcdf(ds, fname='output.nc', variables=None):\n",
    "        \"\"\"\n",
    "        Generic function to save a datatset to one single compressed netcdf file\n",
    "\n",
    "        Args:\n",
    "            fname (str): name of export file\n",
    "            variables (list str): list of variable to export. Default exports all variables\n",
    "        \"\"\"\n",
    "\n",
    "        encod_dict = {}\n",
    "        if variables is None:\n",
    "            variables = list(ds.keys())\n",
    "\n",
    "        for var in variables:\n",
    "            scale_factor, add_offset = compute_scaling_and_offset(ds[var], n=10)\n",
    "            if str(ds[var].dtype)[:3] == 'int':\n",
    "                encod_dict.update({var:{\n",
    "                                   'dtype':ds[var].dtype}})\n",
    "            else:\n",
    "                encod_dict.update({var:{\"zlib\": True,\n",
    "                                       \"complevel\": 9,\n",
    "                                       'dtype':'int16',\n",
    "                                       'scale_factor':scale_factor,\n",
    "                                       'add_offset':add_offset}})\n",
    "        ds[variables].to_netcdf(fname, encoding=encod_dict, engine='h5netcdf')\n",
    "\n",
    "        print(f'---> File {fname} saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bb30cc-c1aa-4d34-b9d3-0fa74b6e62df",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_netcdf(ds_khaeiz, fname='downscaled_nc.nc', variables=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b594db24-06ed-46cc-a39f-bdf0080aafc2",
   "metadata": {},
   "source": [
    "### 10- Extract `Temperature` from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bbcc9a-1501-4292-9014-eef172e460ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_t = ds_khaeiz.t\n",
    "ds_t.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0f9cab-c24b-4b5c-b2e1-92acba566cf6",
   "metadata": {},
   "source": [
    "### 11- Save a variable to geotif file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb933d5-f9fe-474f-affd-523289a30604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray\n",
    "import rioxarray\n",
    "from pyproj import CRS\n",
    "\n",
    "xds = xarray.open_dataset(\"downscaled_nc.nc\")\n",
    "\n",
    "bT = xds['t']\n",
    "bT = bT.rio.set_spatial_dims(x_dim='x', y_dim='y')\n",
    "bT.rio.crs\n",
    "\n",
    "# Define the CRS projection\n",
    "bT.rio.write_crs(\"epsg:32639\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d60d91-216e-4570-a478-2e56e235ce9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the GeoTIFF file: \n",
    "bT.rio.to_raster(r\"temp_raster.tiff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfa0fd4-0a81-4ca9-97f1-a91e8afc2377",
   "metadata": {},
   "source": [
    "## Note:\n",
    "\n",
    "It is possible to improve accuracy by determining "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
