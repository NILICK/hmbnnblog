[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Envinformatics",
    "section": "",
    "text": "Scraping AQI\n\n\n\n\n\n\n\nScraping\n\n\nML\n\n\n\n\nExtracting AQI data from web for data sciences analysis.\n\n\n\n\n\n\nNov 11, 2022\n\n\nMe\n\n\n\n\n\n\n  \n\n\n\n\nUbuntu\n\n\n\n\n\n\n\nUbuntu\n\n\nNotes\n\n\n\n\nMy notes in Ubuntu working\n\n\n\n\n\n\nSep 30, 2022\n\n\nMe\n\n\n\n\n\n\n  \n\n\n\n\nAnalysis process of downscaled MERRA-2 data\n\n\n\n\n\n\n\nDownscaling\n\n\nMERRA-2\n\n\nLDT\n\n\n\n\nThis post is about create own your blog with free resources in Github.\n\n\n\n\n\n\nAug 16, 2021\n\n\nMe\n\n\n\n\n\n\n  \n\n\n\n\nGIS & RS learning and notes\n\n\n\n\n\n\n\nGeospatial\n\n\n\n\nThis post is about GIS and Remote Sensing learning and keynotes of them.\n\n\n\n\n\n\nJul 3, 2021\n\n\nMe\n\n\n\n\n\n\n  \n\n\n\n\nML-DL Resources\n\n\n\n\n\n\n\nML\n\n\nDL\n\n\n\n\nThis post is about resources for machine learning and deep learning from web.\n\n\n\n\n\n\nJul 2, 2021\n\n\nMe\n\n\n\n\n\n\n  \n\n\n\n\nBlogging with Quarto\n\n\n\n\n\n\n\nWeblog\n\n\nQuarto\n\n\nNbdev\n\n\n\n\nCreating weblog in combination of Jupyterlab and Quarto\n\n\n\n\n\n\nMar 1, 2021\n\n\nMe\n\n\n\n\n\n\n  \n\n\n\n\nJupyterlab\n\n\n\n\n\n\n\nJupyterlab\n\n\n\n\nMy notes in Jupyterlab working\n\n\n\n\n\n\nInvalid Date\n\n\nMe\n\n\n\n\n\n\n  \n\n\n\n\nGeospatial Data Address\n\n\n\n\n\n\n\nGeospatial\n\n\n\n\nURLs for geospatial data, always in custructing!\n\n\n\n\n\n\nMar 25, 2021\n\n\nMe\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/analysis_methods/2021-08-26-Anaysis_Process_Merra2.html",
    "href": "posts/analysis_methods/2021-08-26-Anaysis_Process_Merra2.html",
    "title": "Analysis process of downscaled MERRA-2 data",
    "section": "",
    "text": "In this post, I would like to describe full story of my experiences in spatial downscaling of MERRA-2 data. The main spark of using MERRA-2 data refers to the paper of Assessment of drought conditions over Vietnam using standardized precipitation evapotranspiration index, MERRA-2 re-analysis, and dynamic land cover (Manh-Hung Le et al., 2020). Researchers of this paper used spatial rescaled MERRA-2 data from ~50-km to ~1-km and used it for calculation of drought index.\nIn first step, I tried to use Land surface Data Toolkit (LDT). So, based on LDT User Guide, required libraries were installed for setup LDT in personal laptop. Although successfully installation of all necessary libraries in a hard way, but I didn’t success in using LDT to spatial downscaling of MERRA-2 data.\nAfter unsuccessful attempts to use LDT correctly, connection with authors of mentioned paper was seemed a right way. Dr. Hyunglok Kim as one of the paper’s researches warned me that their spatial downscaled of MERRA-2 data was generated from the Land Information System (LIS), not LDT. Specifically, the LDT will just produce some basic information to produce data from LIS. Based on Hyung explanation about producing spatial rescaled data, me seemed to need a supercomputer to do that. With the help of Hyung, temperature and rain monthly data from 2000 to 2020 produced in 0.001 degree (~1 km) of spatial resolution. In the following, the procedure of analysis of this data will describe."
  },
  {
    "objectID": "posts/analysis_methods/2021-08-26-Anaysis_Process_Merra2.html#overall-view-of-data",
    "href": "posts/analysis_methods/2021-08-26-Anaysis_Process_Merra2.html#overall-view-of-data",
    "title": "Analysis process of downscaled MERRA-2 data",
    "section": "Overall view of data",
    "text": "Overall view of data\nSpatial downscaled of MERRA-2 data files was in NetCDF format. So, me preferred to use Xarray python library to check some its properties.\nOpening 252 NetCDF files simultaneously will done with some python libraries.\n\n\nCode\n#collapse\n\n# Import libraries\nimport xarray as xr\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (8,5)\n\n\nModuleNotFoundError: No module named 'xarray'\n\n\nReading files:\n\n\nCode\n#hide\nds = xr.open_mfdataset(\"/media/nilik/78F80520F804DDEE/Student_MSc/Javi/Data/monthly_data/*.nc\")\n\n\n\n\nCode\n#collapse_output\nprint(ds)\n\n\n<xarray.Dataset>\nDimensions:           (time: 252, north_south: 701, east_west: 1001, ensemble: 1)\nCoordinates:\n  * time              (time) datetime64[ns] 2000-01-01 2000-02-01 ... 2020-12-01\n  * ensemble          (ensemble) float32 1.0\nDimensions without coordinates: north_south, east_west\nData variables:\n    lat               (time, north_south, east_west) float32 dask.array<chunksize=(1, 701, 1001), meta=np.ndarray>\n    lon               (time, north_south, east_west) float32 dask.array<chunksize=(1, 701, 1001), meta=np.ndarray>\n    Rainf_f_tavg      (time, ensemble, north_south, east_west) float32 dask.array<chunksize=(1, 1, 701, 1001), meta=np.ndarray>\n    Rainf_f_inst      (time, ensemble, north_south, east_west) float32 dask.array<chunksize=(1, 1, 701, 1001), meta=np.ndarray>\n    Tair_f_tavg       (time, ensemble, north_south, east_west) float32 dask.array<chunksize=(1, 1, 701, 1001), meta=np.ndarray>\n    Tair_f_inst       (time, ensemble, north_south, east_west) float32 dask.array<chunksize=(1, 1, 701, 1001), meta=np.ndarray>\n    TotalPrecip_tavg  (time, ensemble, north_south, east_west) float32 dask.array<chunksize=(1, 1, 701, 1001), meta=np.ndarray>\n    TotalPrecip_inst  (time, ensemble, north_south, east_west) float32 dask.array<chunksize=(1, 1, 701, 1001), meta=np.ndarray>\nAttributes: (12/15)\n    missing_value:           -9999.0\n    NUM_SOIL_LAYERS:         4\n    SOIL_LAYER_THICKNESSES:  [0.1 0.3 0.6 1. ]\n    title:                   LIS land surface model output\n    institution:             NASA GSFC\n    source:                  +template open water\n    ...                      ...\n    comment:                 website: http://lis.gsfc.nasa.gov/\n    MAP_PROJECTION:          EQUIDISTANT CYLINDRICAL\n    SOUTH_WEST_CORNER_LAT:   27.0\n    SOUTH_WEST_CORNER_LON:   47.0\n    DX:                      0.01\n    DY:                      0.01\n\n\nOutput reading fils show that thera are time, north_south, east_west, ensemble as Dimensions, time and ensemble as Coordinates and lat, lon, Rainf_f_tavg, Rainf_f_inst, Tair_f_tavg, Tair_f_inst, TotalPrecip_tavg, TotalPrecip_inst as Data variables of data.\nYou can see all of these items individually as follow:\n\n\nCode\n#collapse_output\nds.dims\n\n\nFrozen({'time': 252, 'north_south': 701, 'east_west': 1001, 'ensemble': 1})\n\n\n\n\nCode\n#collapse_output\nds.coords\n\n\nCoordinates:\n  * time      (time) datetime64[ns] 2000-01-01 2000-02-01 ... 2020-12-01\n  * ensemble  (ensemble) float32 1.0\n\n\n\n\nCode\n#collapse_output\nds.variables\n\n\nFrozen({'lat': <xarray.Variable (time: 252, north_south: 701, east_west: 1001)>\ndask.array<concatenate, shape=(252, 701, 1001), dtype=float32, chunksize=(1, 701, 1001), chunktype=numpy.ndarray>\nAttributes:\n    units:          degree_north\n    standard_name:  latitude\n    long_name:      latitude\n    vmin:           0.0\n    vmax:           0.0, 'lon': <xarray.Variable (time: 252, north_south: 701, east_west: 1001)>\ndask.array<concatenate, shape=(252, 701, 1001), dtype=float32, chunksize=(1, 701, 1001), chunktype=numpy.ndarray>\nAttributes:\n    units:          degree_east\n    standard_name:  longitude\n    long_name:      longitude\n    vmin:           0.0\n    vmax:           0.0, 'time': <xarray.IndexVariable 'time' (time: 252)>\narray(['2000-01-01T00:00:00.000000000', '2000-02-01T00:00:00.000000000',\n       '2000-03-01T00:00:00.000000000', ..., '2020-10-01T00:00:00.000000000',\n       '2020-11-01T00:00:00.000000000', '2020-12-01T00:00:00.000000000'],\n      dtype='datetime64[ns]')\nAttributes:\n    long_name:       time\n    time_increment:  2592000\n    begin_date:      20000101\n    begin_time:      000000, 'ensemble': <xarray.IndexVariable 'ensemble' (ensemble: 1)>\narray([1.], dtype=float32)\nAttributes:\n    units:      ensemble number\n    long_name:  Ensemble numbers, 'Rainf_f_tavg': <xarray.Variable (time: 252, ensemble: 1, north_south: 701, east_west: 1001)>\ndask.array<concatenate, shape=(252, 1, 701, 1001), dtype=float32, chunksize=(1, 1, 701, 1001), chunktype=numpy.ndarray>\nAttributes:\n    units:          kg m-2 s-1\n    standard_name:  rainfall_flux\n    long_name:      rainfall flux\n    vmin:           0.0\n    vmax:           0.02, 'Rainf_f_inst': <xarray.Variable (time: 252, ensemble: 1, north_south: 701, east_west: 1001)>\ndask.array<concatenate, shape=(252, 1, 701, 1001), dtype=float32, chunksize=(1, 1, 701, 1001), chunktype=numpy.ndarray>\nAttributes:\n    units:          kg m-2 s-1\n    standard_name:  rainfall_flux\n    long_name:      rainfall flux\n    vmin:           0.0\n    vmax:           0.02, 'Tair_f_tavg': <xarray.Variable (time: 252, ensemble: 1, north_south: 701, east_west: 1001)>\ndask.array<concatenate, shape=(252, 1, 701, 1001), dtype=float32, chunksize=(1, 1, 701, 1001), chunktype=numpy.ndarray>\nAttributes:\n    units:          K\n    standard_name:  air_temperature\n    long_name:      air temperature\n    vmin:           213.0\n    vmax:           333.0, 'Tair_f_inst': <xarray.Variable (time: 252, ensemble: 1, north_south: 701, east_west: 1001)>\ndask.array<concatenate, shape=(252, 1, 701, 1001), dtype=float32, chunksize=(1, 1, 701, 1001), chunktype=numpy.ndarray>\nAttributes:\n    units:          K\n    standard_name:  air_temperature\n    long_name:      air temperature\n    vmin:           213.0\n    vmax:           333.0, 'TotalPrecip_tavg': <xarray.Variable (time: 252, ensemble: 1, north_south: 701, east_west: 1001)>\ndask.array<concatenate, shape=(252, 1, 701, 1001), dtype=float32, chunksize=(1, 1, 701, 1001), chunktype=numpy.ndarray>\nAttributes:\n    units:          kg m-2 s-1\n    standard_name:  total_precipitation_amount\n    long_name:      total precipitation amount\n    vmin:           0.0\n    vmax:           0.02, 'TotalPrecip_inst': <xarray.Variable (time: 252, ensemble: 1, north_south: 701, east_west: 1001)>\ndask.array<concatenate, shape=(252, 1, 701, 1001), dtype=float32, chunksize=(1, 1, 701, 1001), chunktype=numpy.ndarray>\nAttributes:\n    units:          kg m-2 s-1\n    standard_name:  total_precipitation_amount\n    long_name:      total precipitation amount\n    vmin:           0.0\n    vmax:           0.02})\n\n\n\n\nCode\n#collapse_output\nds.attrs\n\n\n{'missing_value': -9999.0,\n 'NUM_SOIL_LAYERS': 4,\n 'SOIL_LAYER_THICKNESSES': array([0.1, 0.3, 0.6, 1. ], dtype=float32),\n 'title': 'LIS land surface model output',\n 'institution': 'NASA GSFC',\n 'source': '+template open water',\n 'history': 'created on date: 2021-07-10T04:31:27.879',\n 'references': 'Kumar_etal_EMS_2006, Peters-Lidard_etal_ISSE_2007',\n 'conventions': 'CF-1.6',\n 'comment': 'website: http://lis.gsfc.nasa.gov/',\n 'MAP_PROJECTION': 'EQUIDISTANT CYLINDRICAL',\n 'SOUTH_WEST_CORNER_LAT': 27.0,\n 'SOUTH_WEST_CORNER_LON': 47.0,\n 'DX': 0.01,\n 'DY': 0.01}\n\n\nIt is possible to show items for a dimension of our dataset that can be useful in future analysis.\n\n\nCode\n#collapse_output\nprint(ds.time)\n\n\n<xarray.DataArray 'time' (time: 252)>\narray(['2000-01-01T00:00:00.000000000', '2000-02-01T00:00:00.000000000',\n       '2000-03-01T00:00:00.000000000', ..., '2020-10-01T00:00:00.000000000',\n       '2020-11-01T00:00:00.000000000', '2020-12-01T00:00:00.000000000'],\n      dtype='datetime64[ns]')\nCoordinates:\n  * time     (time) datetime64[ns] 2000-01-01 2000-02-01 ... 2020-12-01\nAttributes:\n    long_name:       time\n    time_increment:  2592000\n    begin_date:      20000101\n    begin_time:      000000"
  },
  {
    "objectID": "posts/analysis_methods/2021-08-26-Anaysis_Process_Merra2.html#simple-plotting",
    "href": "posts/analysis_methods/2021-08-26-Anaysis_Process_Merra2.html#simple-plotting",
    "title": "Analysis process of downscaled MERRA-2 data",
    "section": "Simple Plotting",
    "text": "Simple Plotting\nXarray library in combination of matplotlib library has powerful capability to draw various plots. For example in section will show some plots with xarray. Dataset variables show there are three climate variables include air temperature, rainfall and total precipitation. We can plot air temperature in first time as follow.\n\n\nCode\n#collapse\ntemp = ds.Tair_f_tavg\ntemp[0].plot();\n\n\n\n\n\nThere is another way to plot based on specific time.\n\n\nCode\n#hide_output\ntemp = ds.Tair_f_tavg\ntemp.sel(time='2000-01-01').plot();\n\n\n\n\n\nDespite there are lat and lon data variables in dataset, in above plot geographical coordinates have been displayed incorrectly. Because lat and lon are not as dimension, we can not display geographical coordinates correctly. For improve the plot in showing geographical coordinates, mentioned data variables should be set as coords. Furthermore, air temperature unit is in kelvin [K], while we need it as celsius [C]. So it is necessary to convert air temperature unit.\n\n\nCode\n#collapse\n\n# set `lat` and `lon` as coords\nds = ds.set_coords(['lon','lat'])\n\n# convert `air temperature` unit from kelin to celsius\ntemp_c = ds.Tair_f_tavg - 273.15\n\n# plotting `air temperature` data variable in celsius and geographical coordinates.\ntemp_c.sel(time='2000-01-01').plot(x='lon', y='lat');"
  },
  {
    "objectID": "posts/analysis_methods/2021-08-26-Anaysis_Process_Merra2.html#simple-statistics",
    "href": "posts/analysis_methods/2021-08-26-Anaysis_Process_Merra2.html#simple-statistics",
    "title": "Analysis process of downscaled MERRA-2 data",
    "section": "Simple statistics",
    "text": "Simple statistics\nNow, with new dataarray created for air temperature it is possible to compute some statistics for this climate variable such as mean, std, min, max, etc. For example, some air temperature statistics for August 2015 are shown as follow.\n\n\nCode\n#collapse\ntemp_20150825 = temp_c.sel(time='2015-08-01')\ntemp_avg = temp_20150825.mean().values\ntemp_std = temp_20150825.std().values\ntemp_min = temp_20150825.min().values\ntemp_max = temp_20150825.max().values\n\nprint(\"Mean air temperature for August 2015 is\", temp_avg , \"celsius.\\n\"\n     \"Standard deviation of air temperature for August 2015 is\", temp_std ,\".\\n\"\n     \"Minimum air temperature for August 2015 is\", temp_min , \"celsius.\\n\"\n     \"Maximum air temperature for August 2015 is\", temp_max , \"celsius.\")\n\n\nMean air temperature for August 2015 is 31.591408 celsius.\nStandard deviation of air temperature for August 2015 is 4.980299 .\nMinimum air temperature for August 2015 is 21.36026 celsius.\nMaximum air temperature for August 2015 is 40.377167 celsius.\n\n\n\nTip: Our data is monthly from 2000 to 2020.."
  },
  {
    "objectID": "posts/analysis_methods/2021-08-26-Anaysis_Process_Merra2.html#certain-point-values",
    "href": "posts/analysis_methods/2021-08-26-Anaysis_Process_Merra2.html#certain-point-values",
    "title": "Analysis process of downscaled MERRA-2 data",
    "section": "Certain point values",
    "text": "Certain point values\nThe Merre-2 rescaled data is a reanalysis data with contiguous values, so if we want to compare this values with climatic station data as ground values it is important to extract the climate variables from Merra-2 dataset in a specific values in accordance with climatic station latitude and longitude. For extract this value(s) based on certain latitude and longitude we can finding the index of the grid point nearest a specific lat/lon.\nIn this example we want to find air temperature in latitude = 30.66 and longitude = 51.58 for August 2015.\n\n\nCode\n#collapse\n\nlatitude = 30.66\nlongitude = 51.58\n\n#finding the index of the grid point nearest a specific lat/lon.   \nabslat = np.abs(temp_20150825.lat-latitude)\nabslon = np.abs(temp_20150825.lon-longitude)\nc = np.maximum(abslon, abslat)\n([xloc], [yloc]) = np.where(c == np.min(c))\n\n# Using that index location to get the values at the x/y diminsion\npoint_ds = ds.sel(north_south=xloc, east_west=yloc)\n\n# Value of certain point in celsius\ntemp_pnt = point_ds.sel(time='2015-08-01').Tair_f_tavg.values- 273.15\nprint(\"The monthly air temperature in August 2015 for latitude=\", latitude, \" and longitude=\", longitude, \"is\", format(float(temp_pnt), '.2f'), \"celsius.\")\n\n\nThe monthly air temperature in August 2015 for latitude= 30.66  and longitude= 51.58 is 25.74 celsius.\n\n\nWe can also plot for this point in August 2015.\n\n\nCode\n#collapse\n\n# Plot requested lat/lon point blue\ntemp_20150825.plot(x='lon', y='lat')\nplt.scatter(longitude, latitude, color='b')\nplt.text(longitude, latitude, 'requested')\n\n# Plot nearest point in the array red\nplt.scatter(point_ds.lon[0], point_ds.lat[0], color='r')\nplt.text(point_ds.lon[0], point_ds.lat[0], 'nearest')\nplt.title('Temperature at nearest point: %s celsius' % format(float(temp_pnt), '.2f'));\n\n\n\n\n\nThe mean monthly temperature for all time series can also be calculated.\n\n\nCode\n#collapse\n\n# Mean temperature average for specifiv lat/lon\npnt = point_ds.Tair_f_tavg.values - 273.15\nprint(\"The monthly air temperature from 2000 to 2020 for latitude=\", latitude, \" and longitude=\", longitude, \"is\", format(float(pnt.mean()), '.2f'), \"celsius.\")\n\n\nThe monthly air temperature from 2000 to 2020 for latitude= 30.667  and longitude= 51.583 is 14.65 celsius."
  },
  {
    "objectID": "posts/analysis_methods/2021-08-26-Anaysis_Process_Merra2.html#swap-north_south-and-east_west-dimensions-with-lat-and-lon-coordinates",
    "href": "posts/analysis_methods/2021-08-26-Anaysis_Process_Merra2.html#swap-north_south-and-east_west-dimensions-with-lat-and-lon-coordinates",
    "title": "Analysis process of downscaled MERRA-2 data",
    "section": "Swap “north_south” and “east_west” dimensions with “lat” and “lon” coordinates",
    "text": "Swap “north_south” and “east_west” dimensions with “lat” and “lon” coordinates\nOne of the perbolem in working with this dataset is about latitude/longitude. As you saw before there is not any dimension related latitude and longitude and we used set_coords to define lat and lot data variables to plot correctly in geographical coordinates while dataset did not any change in inherent and do any analysis related to latitude and longitude of dataset will have challenges. So, it’s best suggestion to create new dataset with raw data that have latitude and longitude dimensions. Two dimensions include north_south and east_west are linespaces related to latitude and longitude. In this dimensions, from beginning to ending latitude divide based on 0.001 degree distances that first value for north_south set to zero and last value will be based on dividing distances. For example for this dataset zero value of north_south is equal minimum latitude (27.0 degree) and last value (700) is equal maximum latitude (34.0 degree). The east_wet dimension values is also same as north_south but for longitude. So, if we can swap the north_south and east_west dimensions values with original latitude and longitude, respectively, we will have new dataset with original latitude and longitude dimensions.\nFor swapping “north_south” and “east_west” dimensions with lat and lon coordinates there is a Regridder function in xesmf library. Because of multiple NetCDF files should be regridded, so it’s better to done it in a loop.\nAlthough input netcdf files have small size but output netcdf files exported from xarray dataset will be more than x9-10 larger, so for solve this challenge we use zarr library to save output regridded files. But if drop unuseful data variables such as ‘Rainf_f_inst’, ‘Tair_f_inst’, ‘TotalPrecip_inst’ and set remain data variables data type as float32, we can save output file in netcdf format with smaller size.\n\n\nCode\n#collapse\n\nimport numpy as np\nimport xarray as xr\nimport matplotlib.pyplot as plt\nimport xesmf as xe\nimport zarr\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# reading dataset\nds = xr.open_mfdataset(\"/media/nilik/78F80520F804DDEE/Student_MSc/Javi/Data/MERRA_2/monthly_data/*.nc\")\nds = ds.set_coords(['lon','lat'])\n\n# definign outout path\npath_output = '/media/nilik/78F80520F804DDEE/Student_MSc/Javi/Data/MERRA_2/monthly_data/monthly_regrid2/'\n\n# regriding loop\nfor i in range (0, len(ds.time)):\n    dsi = ds.sel(time = ds.time[i])\n    \n    # swap dimensions with multi-dimensional coordinates\n    ds_xy_grid = dsi.rename(north_south='lat', east_west='lon')\n    ds_out = xr.Dataset({'lat': (['lat'], np.linspace(27.0, 34.0, 701)),\n                     'lon': (['lon'], np.linspace(47.0, 57.0, 1001))})\n    \n    regridder = xe.Regridder(ds_xy_grid, ds_out, method='bilinear')\n    ds_lonlat_grid = regridder(ds_xy_grid)\n    ds_lonlat_grid = ds_lonlat_grid.rename(lat='latitude', lon='longitude')\n    \n    # Removing some zero values for plotting correctly\n    ds_lonlat_grid = ds_lonlat_grid.where(ds_lonlat_grid['Tair_f_tavg'] > 0.01, drop=True)\n    ds_lonlat_grid.attrs = dsi.attrs\n    droped = ds_lonlat_grid.drop_vars(['Rainf_f_inst', 'Tair_f_inst', 'TotalPrecip_inst'])\n    \n    # Take date time for name of output file\n    time = str(ds_lonlat_grid.time.values)\n    time = time.removesuffix('T00:00:00.000000000')\n    \n    # save to netcdf\n    encoding = {'Rainf_f_tavg':{'zlib': True, 'complevel': 5, 'dtype': 'float32'},\n                'Tair_f_tavg':{'zlib': True, 'complevel': 5, 'dtype': 'float32'},\n                'TotalPrecip_tavg':{'zlib': True, 'complevel': 5, 'dtype': 'float32'}}\n    \n    droped.to_netcdf((path_output + \"regrid_merra_\" + time + \".nc\"),encoding=encoding)\n    \n    del ds_xy_grid, ds_out, regridder, ds_lonlat_grid, time, encoding, droped\n\n\n\nImproved Above Code\nNOTE: The below code in Jupyterlab app desktop with python 8 did not work correctly but it worked in jupyterlab in browser with python 3.9.5 correctly.\n\n\nCode\n# reading dataset\nds = xr.open_mfdataset(\"/media/nilik/78F80520F804DDEE/Student_MSc/Javi/Data/MERRA_2/monthly_data/*.nc\")\nds = ds.set_coords(['lon','lat'])\n\n# definign outout path\npath_output = '/media/nilik/78F80520F804DDEE/Student_MSc/Javi/Data/MERRA_2/monthly_data/monthly_regrid3/'\n\n# regriding loop\nfor i in range (0, len(ds.time)):\n    dsi = ds.sel(time = ds.time[i])\n    \n    # swap dimensions with multi-dimensional coordinates\n    ds_xy_grid = dsi.rename(north_south='lat', east_west='lon')    \n    ds_out = xr.Dataset({'lat': (['lat'], np.linspace(27.0, 34.0, 701)),\n                     'lon': (['lon'], np.linspace(47.0, 57.0, 1001))})\n    \n    regridder = xe.Regridder(ds_xy_grid, ds_out, method='bilinear')\n    ds_lonlat_grid = regridder(ds_xy_grid)\n    ds_lonlat_grid = ds_lonlat_grid.rename(lat='latitude', lon='longitude')\n    \n    # Removing some zero values for plotting correctly\n    ds_lonlat_grid = ds_lonlat_grid.where(ds_lonlat_grid['Tair_f_tavg'] > 0.01, drop=True)\n    #dropnan1 = ds_lonlat_grid.dropna('longitude', how = 'any')\n    #dropnan2 = dropnan1.dropna('latitude', how = 'any')\n    ds_lonlat_grid.attrs = dsi.attrs\n    droped = ds_lonlat_grid.drop_vars(['Rainf_f_inst', 'Tair_f_inst', 'TotalPrecip_inst'])\n    expanded_da = xr.concat([droped], 'time') # add 'time' dimension\n    #resample_monthly = expanded_da.resample(time='1M').max()\n    final_ds = expanded_da.squeeze(dim='ensemble', drop=False) # drop 'ensemble' dimension\n    \n    # Take date time for name of output file\n    time = str(ds_lonlat_grid.time.values)\n    time = time.removesuffix('T00:00:00.000000000')\n    \n    # save to netcdf\n    encoding = {'Rainf_f_tavg':{'zlib': True, 'complevel': 5, 'dtype': 'float32'},\n                'Tair_f_tavg':{'zlib': True, 'complevel': 5, 'dtype': 'float32'},\n                'TotalPrecip_tavg':{'zlib': True, 'complevel': 5, 'dtype': 'float32'}}\n    \n    final_ds.to_netcdf((path_output + \"regrid_merra_\" + time + \".nc\"),encoding=encoding)\n    \n    del ds_xy_grid, ds_out, regridder, ds_lonlat_grid, time, encoding, droped, expanded_da, final_ds\n\n\nComparison between raw and regreded MERRA-2 data are plotted in below. The July 2009 selected for comparison.\n\n\nCode\n# collapse\n\nds_raw = xr.open_dataset('/media/nilik/78F80520F804DDEE/Student_MSc/Javi/Data/monthly_data/LIS_HIST_200906010000.d01.nc')\nds_reg = xr.open_dataset('/media/nilik/78F80520F804DDEE/Student_MSc/Javi/Data/monthly_data/monthly_regrid/regrid_merra_2009-06-01.nc')\n\n# Compare two plots\nfig, axes = plt.subplots(ncols=2, figsize=(10, 4))\n\nds_raw.Tair_f_tavg.plot(ax=axes[0])\naxes[0].set_title(\"Raw data\")\n\nds_reg.Tair_f_tavg.plot(ax=axes[1])\naxes[1].set_title(\"Regrided data\")\n\nfig.tight_layout()\n\n\n\n\n\nNow we can select a random point in above plots and extract its air temperature and rain values for more exactly comparison.\n\n\nCode\n# collapse\n\n# defining a random point for extract climatic variables\nlatitude = 30.48\nlongitude = 50.58\n\n# raw data\nabslat = np.abs(ds_raw.lat-latitude)\nabslon = np.abs(ds_raw.lon-longitude)\nc = np.maximum(abslon, abslat)\n([xloc], [yloc]) = np.where(c == np.min(c))\npnt_raw = ds_raw.sel(north_south=xloc, east_west=yloc)\ntemp_raw = pnt_raw.Tair_f_tavg.values\nrain_raw = pnt_raw.Rainf_f_tavg.values\n\n# regrided data\npnt_reg = ds_reg.where((ds_reg.longitude==longitude) & (ds_reg.latitude==latitude), drop=True)\ntemp_reg = pnt_reg.Tair_f_tavg.values\nrain_reg = pnt_reg.Rainf_f_tavg.values\n\nprint(\"The air temperature in raw Merra-2 is \", format(float(temp_raw), '.2f'),\"\\n\"\n     \"The air temperature in regrided Merra-2 is \", format(float(temp_reg), '.2f'),\"\\n\"\n     \"The rain in raw Merra-2 is \", format(float(rain_raw), '.2f'),\"\\n\"\n     \"The rain in regrided Merra-2 is \", format(float(rain_reg), '.2f'))\n\n\nThe air temperature in raw Merra-2 is  303.64 \nThe air temperature in regrided Merra-2 is  303.64 \nThe rain in raw Merra-2 is  0.00 \nThe rain in regrided Merra-2 is  0.00"
  },
  {
    "objectID": "posts/analysis_methods/2021-08-26-Anaysis_Process_Merra2.html#integrated-surface-dataset-global",
    "href": "posts/analysis_methods/2021-08-26-Anaysis_Process_Merra2.html#integrated-surface-dataset-global",
    "title": "Analysis process of downscaled MERRA-2 data",
    "section": "Integrated Surface Dataset (Global)",
    "text": "Integrated Surface Dataset (Global)\nOur data preparation till here was about MERRA-2 dataset. As mentioned earlier, MERRA-2 data type is reanalysis data, since we downscaled this data spatially, verifying this data with real data is necessary. The best database for real hourly climate variables is The Integrated Surface Dataset (ISD). According to its website, ISD is composed of worldwide surface weather observations from over 35,000 stations, though the best spatial coverage is evident in North America, Europe, Australia, and parts of Asia. Parameters included are: air quality, atmospheric pressure, atmospheric temperature/dew point, atmospheric winds, clouds, precipitation, ocean waves, tides and more. ISD refers to the data contained within the digital database as well as the format in which the hourly, synoptic (3-hourly), and daily weather observations are stored. ISD provides hourly data that can be used in a wide range of climatological applications. For some stations, data may go as far back as 1901, though most data show a substantial increase in volume in the 1940s and again in the early 1970s. Currently (2021-08-17), there are over 14,000 “active” stations updated daily in the database.\nIn our study area boundary, there is 20 stations for surface weather observations. The air temperature and rainfall was downloaded for this stations in target time period. This data need preparation to use in analysis. The vaex library is a useful python package for work with large data with low memory usage. We used this library for preparation of surface weather data.\n\n\nCode\n#collapse_output\n\nimport vaex\ndfv = vaex.from_csv('/media/nilik/78F80520F804DDEE/Student_MSc/Javi/Data/Hourly Surface Station Data/2654018.csv')\ndfv\n\n\n/home/nilik/MYPROGRAMS/miniconda3/envs/envinfo/lib/python3.9/site-packages/vaex/__init__.py:524: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n  return _from_csv_read(filename_or_buffer=filename_or_buffer, copy_index=copy_index,\n\n\n\n\n\n#                                    STATION    NAME                           LATITUDE  LONGITUDE  ELEVATION  DATE               SOURCE  REPORT_TYPE  CALL_SIGN  QUALITY_CONTROL  TMP    \n\n\n0        40875099999BANDAR ABBASS INTERNATIONAL, IR27.218169 56.377875  6.7        2000-01-01T00:00:004       FM-12        OIKB       V020             +0142,1\n1        40875099999BANDAR ABBASS INTERNATIONAL, IR27.218169 56.377875  6.7        2000-01-01T07:00:004       FM-15        OIKB       V020             +0260,1\n2        40875099999BANDAR ABBASS INTERNATIONAL, IR27.218169 56.377875  6.7        2000-01-01T08:00:004       FM-15        OIKB       V020             +0280,1\n3        40875099999BANDAR ABBASS INTERNATIONAL, IR27.218169 56.377875  6.7        2000-01-01T09:00:004       FM-15        OIKB       V020             +0290,1\n4        40875099999BANDAR ABBASS INTERNATIONAL, IR27.218169 56.377875  6.7        2000-01-01T10:00:004       FM-15        OIKB       V020             +0300,1\n...                                  ...        ...                            ...       ...        ...        ...                ...     ...          ...        ...              ...    \n2,480,20940836199999PERSIAN GULF AIRPORT, IR       27.366666652.7333333 8.0        2020-12-31T14:00:004       FM-15        99999      V020             +0220,1\n2,480,21040836199999PERSIAN GULF AIRPORT, IR       27.366666652.7333333 8.0        2020-12-31T15:00:004       FM-15        99999      V020             +0200,1\n2,480,21140836199999PERSIAN GULF AIRPORT, IR       27.366666652.7333333 8.0        2020-12-31T16:00:004       FM-15        99999      V020             +0180,1\n2,480,21240836199999PERSIAN GULF AIRPORT, IR       27.366666652.7333333 8.0        2020-12-31T17:00:004       FM-15        99999      V020             +0160,1\n2,480,21340836199999PERSIAN GULF AIRPORT, IR       27.366666652.7333333 8.0        2020-12-31T18:00:004       FM-15        99999      V020             +0150,1\n\n\n\n\nThe name of surface weather stations are:\n\n\nCode\n# collapse\ndfv.NAME.unique()\n\n\n['BANDAR ABBASS INTERNATIONAL, IR',\n 'KERMAN, IR',\n 'RAFSANJAN, IR',\n 'LAMERD, IR',\n 'SIRJAN, IR',\n 'BUSHEHR, IR',\n 'SHIRAZ SHAHID DASTGHAIB INTERNATIONAL, IR',\n 'JAM, IR',\n 'FASA, IR',\n 'YASOGE, IR',\n 'ABADEH, IR',\n 'BANDAR E DAYYER, IR',\n 'BAFT, IR',\n 'GACHSARAN, IR',\n 'LAR, IR',\n 'FARSI ISLAND, IR',\n 'YASOUJ, IR',\n 'KHARG, IR',\n 'ASALOYEH, IR',\n 'PERSIAN GULF AIRPORT, IR']\n\n\nSome columns in this data should be changed, you can see preparation commands in follow.\nCounting values for each station:\n\n\nCode\n# collapse_output\nstation_count = dfv.groupby(by='NAME').agg({'count':'count'})\nfor x in range(len(station_count)):\n    print (station_count[x])\n\n\n['BUSHEHR, IR', 267359]\n['YASOGE, IR', 9650]\n['JAM, IR', 54130]\n['BANDAR E DAYYER, IR', 33972]\n['FASA, IR', 190922]\n['YASOUJ, IR', 166293]\n['BAFT, IR', 53720]\n['GACHSARAN, IR', 149147]\n['ASALOYEH, IR', 2]\n['SHIRAZ SHAHID DASTGHAIB INTERNATIONAL, IR', 407263]\n['KHARG, IR', 74317]\n['PERSIAN GULF AIRPORT, IR', 97346]\n['LAR, IR', 152458]\n['FARSI ISLAND, IR', 15]\n['BANDAR ABBASS INTERNATIONAL, IR', 335261]\n['ABADEH, IR', 110148]\n['LAMERD, IR', 32682]\n['KERMAN, IR', 273070]\n['RAFSANJAN, IR', 18811]\n['SIRJAN, IR', 53648]\n\n\nChecking temperature column data type:\n\n\nCode\n# collapse_output\ndfv['TMP'].data_type\n\n\n<bound method Expression.data_type of Expression = TMP\nLength: 2,480,214 dtype: string (column)\n----------------------------------------\n      0  +0142,1\n      1  +0260,1\n      2  +0280,1\n      3  +0290,1\n      4  +0300,1\n      ...       \n2480209  +0220,1\n2480210  +0200,1\n2480211  +0180,1\n2480212  +0160,1\n2480213  +0150,1\n>\n\n\nIt’s need to be changed the temperature column data type from string to float. So, the ‘Temp’ column values was splitted and then was built new temperature column with correct values.\n\n\nCode\n# collapse_output\ndfv['Temp_C'] = dfv[\"TMP\"].str.split(\",\").apply(lambda x: x[0])\ndfv['Temp_C'].astype('float32')\n\n\nExpression = astype(Temp_C, 'float32')\nLength: 2,480,214 dtype: float32 (expression)\n---------------------------------------------\n      0  142\n      1  260\n      2  280\n      3  290\n      4  300\n    ...     \n2480209  220\n2480210  200\n2480211  180\n2480212  160\n2480213  150\n\n\nThen, we convert temperature values to celsius degree.\n\n\nCode\n#collapse_output\ndfv['Temp_C_2'] = (dfv['Temp_C'].astype('float32'))/10\n\n\nChecking DATA column data type:\n\n\nCode\n# collapse_output\ndfv.DATE.data_type\n\n\n<bound method Expression.data_type of Expression = DATE\nLength: 2,480,214 dtype: string (column)\n----------------------------------------\n      0  2000-01-01T00:00:00\n      1  2000-01-01T07:00:00\n      2  2000-01-01T08:00:00\n      3  2000-01-01T09:00:00\n      4  2000-01-01T10:00:00\n            ...             \n2480209  2020-12-31T14:00:00\n2480210  2020-12-31T15:00:00\n2480211  2020-12-31T16:00:00\n2480212  2020-12-31T17:00:00\n2480213  2020-12-31T18:00:00\n>\n\n\nThe data type of DATA column should be in datetime64 format, so it was changed.\n\n\nCode\n# collapse\ndfv['DATE']=dfv.DATE.astype('datetime64[ns]')\n\n\nAfter finalizing preparation of surface data observations, it was saved as a new CSV file.\n\n\nCode\n# collpase\ndfv.export_csv(\"/media/nilik/78F80520F804DDEE/Student_MSc/Javi/Data/Hourly Surface Station Data/improved_stations.csv\")"
  },
  {
    "objectID": "posts/analysis_methods/2021-08-26-Anaysis_Process_Merra2.html#comparison-of-merra-2-data-with-surface-data-observation-data",
    "href": "posts/analysis_methods/2021-08-26-Anaysis_Process_Merra2.html#comparison-of-merra-2-data-with-surface-data-observation-data",
    "title": "Analysis process of downscaled MERRA-2 data",
    "section": "Comparison of MERRA-2 data with surface data observation data",
    "text": "Comparison of MERRA-2 data with surface data observation data\nAfter regriding MERRA-2 data and cleaning surface observation data, we can compare these data based on station latitude and longitude. For example we want to compare air temperature in Shiraz station for November 2018.\n\n\nCode\n# collapse\n\n# Import libraries\nimport vaex\nimport numpy as np\nimport xarray as xr\nimport matplotlib.pyplot as plt\nimport xesmf as xe\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Opening surface data observations\ndfv = vaex.from_csv('/media/nilik/78F80520F804DDEE/Student_MSc/Javi/Data/Hourly Surface Station Data/improved_stations.csv')\n\n# Opening Merra-2 data\nds = xr.open_mfdataset(\"/media/nilik/78F80520F804DDEE/Student_MSc/Javi/Data/monthly_data/*.nc\")\nds = ds.set_coords(['lon','lat'])\n\n########## Extracting data from surface weather observation data ##########\n\n# Changing 'DATE' column data type from string to datetime64 \ndfv['DATE']=dfv.DATE.astype('datetime64[ns]')\n\n# Filtering dataframe based on 'NAME' column\nstation_name = 'LAMERD, IR'\nstation = dfv[dfv.NAME == str(station_name)]\n\n# Select a certain month data\nstart_date = np.datetime64('2018-11-01 00:00:00')\nend_date = np.datetime64('2018-11-30 23:00:00')\n\nstartDATE = station[(station.DATE > start_date)]\nrangeDATE = startDATE[(startDATE.DATE < end_date)]\n\n# Drop nan values (999.9)\nedit = rangeDATE[rangeDATE.Temp_C < np.float64(100)]\n\n# Calculate monthly mean temperature for 2018-11\ntrmp_2018_11 = edit.mean(edit['Temp_C'])\n\n# Print surface monthly air temperature\nprint('Surface monthly air temperature for [', station_name, '] is: ', format(float(trmp_2018_11), '.2f'))\n\n########## Extracting data from rrgrided MERRA-2 data ##########\n\n# Sekecting target month\nds201811 = ds.sel(time='2018-11-01')\n\n# Extracting minimum and maximum of lat/lon\nmin_lon = ds201811.lon.min().values\nmin_lat = ds201811.lat.min().values\nmax_lon = ds201811.lon.max().values\nmax_lat = ds201811.lat.max().values\n\n# swap dimensions with multi-dimensional coordinates\nds_xy_grid = ds201811.rename(north_south='lat', east_west='lon')\nds_out = xr.Dataset({'lat': (['lat'], np.linspace(float(min_lat), float(max_lat), int(ds201811.north_south.count()))),\n                     'lon': (['lon'], np.linspace(float(min_lon), float(max_lon), int(ds201811.east_west.count())))})\n                     \nregridder = xe.Regridder(ds_xy_grid, ds_out, method='bilinear')\nds_lonlat_grid = regridder(ds_xy_grid)\nds_lonlat_grid = ds_lonlat_grid.rename(lat='latitude', lon='longitude')\n\n# Extracting latitude and longitude values based on the dataframe of target station\nlatitude = station.LATITUDE.unique()[0]\nlongitude = station.LONGITUDE.unique()[0]\nlatitude = round(latitude, 2)\nlongitude = round(longitude, 2)\n\n# Extracting the air temperature from merra-2 data\npnts = ds_lonlat_grid.where((ds_lonlat_grid.longitude==longitude) & (ds_lonlat_grid.latitude==latitude), drop=True)\ncelsius = (pnts.Tair_f_tavg.values) - 273.15\n\n# Print MERRA-2 monthly air temperature\nprint('MERRA-2 monthly air temperature for [', station_name, '] is: ', format(float(celsius), '.2f'))\n\n\nSurface monthly air temperature for [ LAMERD, IR ] is:  23.44\nMERRA-2 monthly air temperature for [ LAMERD, IR ] is:  27.52\n\n\nIn above example we compared real and reanalused air temperature for one location in a specific time, but it’s ideal to compare all locations in all date time period. So, first we will try to extract the real air temperature for all locations in all time and then extract these values from MERRA-2 data. Finally we’ll try to compare all of data in one plot."
  },
  {
    "objectID": "posts/analysis_methods/2021-08-26-Anaysis_Process_Merra2.html#extract-surface-temperature-values-for-each-station-in-all-252-months",
    "href": "posts/analysis_methods/2021-08-26-Anaysis_Process_Merra2.html#extract-surface-temperature-values-for-each-station-in-all-252-months",
    "title": "Analysis process of downscaled MERRA-2 data",
    "section": "Extract surface temperature values for each station in all 252 months",
    "text": "Extract surface temperature values for each station in all 252 months\nWith this code we can plot monthly air temperature of surface weather stations (real data) year by year.\n\n\nCode\n#collapse\n\n# Import libraries\nimport pandas as pd\nimport numpy as np\nimport hvplot.pandas\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Opening surface data observations\ndf_station = pd.read_csv('/media/nilik/78F80520F804DDEE/Student_MSc/Javi/Data/Hourly Surface Station Data/improved_stations.csv')\n\n# Changing 'DATE' column data type from string to datetime64 \ndf_station['DATE']=df_station.DATE.astype('datetime64[ns]')\n\n# there is one station with two name, improve it!\ndf_station.NAME[df_station.NAME=='YASOUJ, IR'] = 'YASOGE, IR'\n\n# Drop nan values (999.9)\ndf_station = df_station[df_station.Temp_C < np.float64(100)]\n\n# Calculate monthly mean temperature in each year\nmean_month_staion = df_station.groupby([df_station.DATE.dt.month, df_station.DATE.dt.year,\n                                 df_station.NAME, round(df_station.LATITUDE, 2), round(df_station.LONGITUDE, 2)])[\"Temp_C\"].mean()\nmean_month_staion = mean_month_staion.rename_axis(['MONTH', 'YEAR', 'NAME', 'LATITUDE', 'LONGITUDE'])\n#mean_month_staion.hvplot.line(x = 'MONTH', y= 'Temp_C', groupby=['NAME', 'YEAR'])"
  },
  {
    "objectID": "posts/analysis_methods/2021-08-26-Anaysis_Process_Merra2.html#extract-merra-2-temperature-values-for-each-station-in-all-252-months",
    "href": "posts/analysis_methods/2021-08-26-Anaysis_Process_Merra2.html#extract-merra-2-temperature-values-for-each-station-in-all-252-months",
    "title": "Analysis process of downscaled MERRA-2 data",
    "section": "Extract MERRA-2 temperature values for each station in all 252 months",
    "text": "Extract MERRA-2 temperature values for each station in all 252 months\nWith these two below codes we can extract monthly air temperature from MERRA-2 dataset based on surface weather stations latitude and longitude and then plot them year by year.\n\n\nCode\n# collapse\n\n# import required libraries\nimport xarray as xr\nimport pandas as pd\nimport numpy as np\nimport xesmf as xe\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom tqdm import tqdm\n\n# reading MERRA-2 dataset\nds = xr.open_mfdataset(\"/media/nilik/78F80520F804DDEE/Student_MSc/Javi/Data/monthly_data/*.nc\")\nds = ds.set_coords(['lon','lat'])\n\n# Extracting latitude and longitude of surface weather stations\ndf = pd.read_csv('/media/nilik/78F80520F804DDEE/Student_MSc/Javi/Data/Hourly Surface Station Data/improved_stations.csv')\ndf.NAME[df.NAME=='YASOUJ, IR'] = 'YASOGE, IR'\n\ndf_merra = {'NAME': [], 'time': [],\n            'mean_monthly_temp':[], 'lot':[], 'lon':[]}\n# regriding loop\nfor i in tqdm(range(len(ds.time))):\n    dsi = ds.sel(time = ds.time[i])\n    \n    # Extracting minimum and maximum of lat/lon\n    min_lon = dsi.lon.min().values\n    min_lat = dsi.lat.min().values\n    max_lon = dsi.lon.max().values\n    max_lat = dsi.lat.max().values\n    \n    # swap dimensions with multi-dimensional coordinates\n    ds_xy_grid = dsi.rename(north_south='lat', east_west='lon')\n    ds_out = xr.Dataset({'lat': (['lat'], np.linspace(float(min_lat),\n                                                      float(max_lat), int(dsi.north_south.count()))),\n                         'lon': (['lon'], np.linspace(float(min_lon),\n                                                      float(max_lon), int(dsi.east_west.count())))})\n\n    \n    regridder = xe.Regridder(ds_xy_grid, ds_out, method='bilinear')\n    ds_lonlat_grid = regridder(ds_xy_grid)\n    ds_lonlat_grid = ds_lonlat_grid.rename(lat='latitude', lon='longitude')\n    \n    # Extracting latitude and longitude of surface weather stations\n    for x in range (len(df.NAME.unique())):\n        # Filtering dataframe based on 'NAME' column\n        station_name = df.NAME.unique()[x]\n        station = df[df.NAME == str(station_name)]\n        latitude = station.LATITUDE.unique()[0]\n        longitude = station.LONGITUDE.unique()[0]\n        latitude = round(latitude, 2)\n        longitude = round(longitude, 2)\n\n        # Extracting the air temperature from merra-2 data\n        pnts = ds_lonlat_grid.where((ds_lonlat_grid.longitude==longitude) &\n                                    (ds_lonlat_grid.latitude==latitude), drop=True)\n        temp_value = pnts.Tair_f_tavg.values\n        if temp_value.size == 0:\n            celsius = -9999.99\n        else:\n            celsius = float((pnts.Tair_f_tavg.values) - 273.15)\n        \n        \n        #print(station_name, dsi.time.values, str(pnts.Tair_f_tavg.values), latitude, longitude)\n        #data = {\"NAME\": station_name, 'time': str(dsi.time.values),\n        #                     'mean_monthly_temp':celsius, 'lot':latitude, 'lon':longitude}\n        df_merra['NAME'].append(station_name)\n        df_merra['time'].append(str(dsi.time.values))\n        df_merra['mean_monthly_temp'].append(celsius)\n        df_merra['lat'].append(latitude)\n        df_merra['lon'].append(longitude)\n\n        del station_name, station, latitude, longitude, pnts, celsius\n        \n    del dsi, min_lon, min_lat, max_lon, max_lat, ds_xy_grid, ds_out, regridder, ds_lonlat_grid\n\n# Save output as a CSV file\ndf_merra2 = pd.DataFrame.from_dict(df_merra)\ndf_merra2.to_csv('./data/monthly_merra2_stations.csv')\n\n\n\n\nCode\n# collapse\n\n# Import libraries\nimport pandas as pd\nimport numpy as np\nimport hvplot.pandas\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Opening surface data observations\ndf_merra = pd.read_csv('./data/monthly_merra2_stations.csv')\n\n# Changing 'DATE' column data type from string to datetime64 \ndf_merra['time']=df_merra.time.astype('datetime64[ns]')\n\n# Drop nan values (-9999.99)\ndf_merra = df_merra[df_merra.mean_monthly_temp > np.float64(-9999.99)]\ndf_merra.drop(['Unnamed: 0'], axis=1)\n# Calculate monthly mean temperature in each year\nmean_month_merra = df_merra.groupby([df_merra.time.dt.month, df_merra.time.dt.year,\n                               df_merra.NAME, df_merra.lot, df_merra.lon])[\"mean_monthly_temp\"].mean()\nmean_month_merra = mean_month_merra.rename_axis(['MONTH', 'YEAR', 'NAME', 'LATITUDE', 'LONGITUDE'])\n#mean_month_merra.hvplot.line(x = 'MONTH', y= 'mean_monthly_temp', groupby=['NAME', 'YEAR'])\n\n\nNow, we can plot monthly air temperature of MERRA-2 data and surface weather stations simultaneously.\n\n\nCode\n# collapse\nimport panel as pn\n\nmean_month_all = pd.concat([mean_month_staion, mean_month_merra], axis=1)\nplt_station = mean_month_all.hvplot.line(x = 'MONTH', y= 'Temp_C' ,\n                                 groupby=['NAME', 'YEAR'], label='Surface Stations')\nplt_merra = mean_month_all.hvplot.line(x = 'MONTH', y= 'mean_monthly_temp' ,\n                                 groupby=['NAME', 'YEAR'], label='MERRA-2 Reanalysis')\ncompare_plots = (plt_station * plt_merra).opts(legend_position='top_left')\n\n# Using panel\nhv_panel = pn.panel(compare_plots, widget_location='top_left')\nhv_panel.save('../_pages/htmls_plots/compare_plots.html', embed=True)"
  },
  {
    "objectID": "posts/analysis_methods/2021-08-26-Anaysis_Process_Merra2.html#plotting-monthly-air-temperature-of-real-data-vs-reanalysis-data",
    "href": "posts/analysis_methods/2021-08-26-Anaysis_Process_Merra2.html#plotting-monthly-air-temperature-of-real-data-vs-reanalysis-data",
    "title": "Analysis process of downscaled MERRA-2 data",
    "section": "Plotting Monthly Air Temperature of Real Data VS Reanalysis DATA",
    "text": "Plotting Monthly Air Temperature of Real Data VS Reanalysis DATA\n\n\nCode\n#hide_input\nfrom IPython.display import IFrame\nIFrame(src='./compare_plots.html', width=1000, height=500)\n\n\n\n        \n        \n\n\nIt seems that we have a problem with these data! Both patterns of variation in monthly data are similar but with one month lag in each other. Because of this problem, I checked data. In surface weather station we have hourly data that mean monthly data was aggregated from these hourly data. In downscaled merra-2 data we time dimension array of first day of each month such as 2000-01-01T00:00:00.000000000, I assumed that each mean temperature for each item of time in merra-2 data is for its past month, so I changed the time of merra-2 data with below code and then compared the monthly mean air temperature from surface weather stations with new merra-2 data.\n\n\nCode\n# collapse\n\n# Import libraries\nimport pandas as pd\nimport numpy as np\nimport hvplot.pandas\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Opening surface data observations\ndf_merra_new = pd.read_csv('./data/monthly_merra2_stations.csv')\n\n# Changing 'DATE' column data type from string to datetime64 \ndf_merra_new['time']=df_merra_new.time.astype('datetime64[ns]')\n\n# Drop nan values (-9999.99)\ndf_merra_new = df_merra_new[df_merra_new.mean_monthly_temp > np.float64(-9999.99)]\ndf_merra_new.drop(['Unnamed: 0'], axis=1)\n\n\ndf_merra_new['time'] = df_merra_new.time + pd.DateOffset(months=-1)\ndf_merra_new = df_merra_new[df_merra_new['time'] > '1999-12-01']\n\n# Calculate monthly mean temperature in each year\nmean_month_merra_new = df_merra_new.groupby([df_merra_new.time.dt.month, df_merra_new.time.dt.year,\n                               df_merra_new.NAME, df_merra_new.lot, df_merra_new.lon])[\"mean_monthly_temp\"].mean()\nmean_month_merra_new = mean_month_merra_new.rename_axis(['MONTH', 'YEAR', 'NAME', 'LATITUDE', 'LONGITUDE'])\n#mean_month_merra.hvplot.line(x = 'MONTH', y= 'mean_monthly_temp', groupby=['NAME', 'YEAR'])\n\n# compare plots\nmean_month_all_new = pd.concat([mean_month_staion, mean_month_merra_new], axis=1)\nab1 = mean_month_all_new.hvplot.line(x = 'MONTH', y= 'Temp_C' ,\n                                 groupby=['NAME', 'YEAR'], label='Station')\nab2 = mean_month_all_new.hvplot.line(x = 'MONTH', y= 'mean_monthly_temp' ,\n                                 groupby=['NAME', 'YEAR'], label='MERRA-2')\ncompare_plots_new = (ab1 * ab2).opts(legend_position='top_left')\n\n# Using panel\nhv_panel_new = pn.panel(compare_plots_new, widget_location='top_left')\nhv_panel_new.save('../_pages/htmls_plots/compare_plots_changed_merra_time.html', embed=True)\n\n\n\n\nCode\n#hide_input\nfrom IPython.display import IFrame\nIFrame(src='https://nilick.github.io/hmbnn-blog/_pages/htmls_plots/compare_plots_changed_merra_time.html', width=1000, height=500)\n\n\n\n        \n        \n\n\nIn follow you can see the time series of hourly surface weather station data availability identified by station name.\n\n\nCode\n# collapse\n\nimport pandas as pd\nimport hvplot.pandas\nfrom IPython.core.display import display, HTML\ndisplay(HTML(\"<style>.container { width:100% !important; }</style>\"))\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\ndf = pd.read_csv('/media/nilik/78F80520F804DDEE/Student_MSc/Javi/Data/Hourly Surface Station Data/improved_stations.csv')\n\n# remove max value of temperature as NAN value\ndf = df[df.Temp_C != 999.9]\n\n# there is one station with two name, improve it!\ndf.NAME[df.NAME=='YASOUJ, IR'] = 'YASOGE, IR'\n\ndf['time_hour'] = pd.to_datetime(df['DATE']).dt.hour\ndf['time_day'] = pd.to_datetime(df['DATE']).dt.day\ndf['time_month'] = pd.to_datetime(df['DATE']).dt.month\ndf['time_year'] = pd.to_datetime(df['DATE']).dt.year\n\n# Plot time series of data\nscaterplot = df.hvplot.scatter(x='time_hour', y='time_day',groupby=['NAME','time_year', 'time_month'])\n\n# Using panel\nscatter_panel = pn.panel(scaterplot, widget_location='top_left')\nscatter_panel.save('../_pages/htmls_plots/scatterplot.html', embed=True)\n\n\n\n\nCode\n#hide_input\nfrom IPython.display import IFrame\nIFrame(src='https://nilick.github.io/hmbnn-blog/_pages/htmls_plots/scatterplot.html', width=1000, height=550)\n\n\n\n        \n        \n\n\n\n\nCode\n# hide_input\n\n################## Convert CSV file to NetCDF file ##################\n# import libraries\nimport os\nimport glob\nimport pandas as pd\nimport numpy as np\nimport xarray as xr\nimport hvplot.xarray\nimport holoviews as hv\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Opening surface data observations\npath_file = '/media/nilik/78F80520F804DDEE/Student_MSc/Javi/Data/Hourly Surface Station Data/'\ndf = pd.read_csv(path_file + 'improved_stations.csv')\n\n# convert DATE column to datetime\ndf['DATE'] = pd.to_datetime(df['DATE'])\n\n# set Date as index\ndf = df.set_index('DATE')\n\n# remove max value of temperature as NAN value\ndf = df[df.Temp_C != 999.9]\n\n# there is one station with two name, improve it!\ndf.NAME[df.NAME=='YASOUJ, IR'] = 'YASOGE, IR'\n\n# Stations name as a list\nstations = df.NAME.unique()\n\n# output path\noutput_path = '/media/nilik/78F80520F804DDEE/Student_MSc/Javi/Data/Hourly Surface Station Data/Final_Imporoved_CSV/'\n\nfor i in stations:\n    dfi = df[df['NAME']==i]\n    \n    # remove duplicate\n    dfi_clean = dfi[~dfi.index.duplicated(keep='first')]\n    \n    # convert latitude and lonfitude column to eastin and northing respectively, these new columns will used for plotting points with leaflet library\n    dfi_clean[\"easting\"], dfi_clean[\"northing\"] = hv.Tiles.lon_lat_to_easting_northing(dfi_clean[\"LONGITUDE\"], dfi_clean[\"LATITUDE\"])\n    \n    # drop 'year', 'month', 'day', 'hour', 'SOURCE', 'REPORT_TYPE', 'CALL_SIGN', 'QUALITY_CONTROL' and 'TMP' columns\n    df_export = dfi_clean.drop(['SOURCE', 'REPORT_TYPE', 'CALL_SIGN', 'QUALITY_CONTROL', 'TMP'], axis=1)\n    \n    # add a column with station name\n    df_export['station'] = str(i)\n\n    # Save final modified (remove NAN & duplicated values)\n    df_export.to_csv(output_path + i + '.csv', sep='\\t')\n    \n    del dfi, dfi_clean, df_export\n\n##### save CSV file stations as NetCDF file\n\nall_files = glob.glob(os.path.join(output_path, \"*.csv\"))\n\nfor filename in all_files:\n    namecsv = os.path.splitext(os.path.basename(filename))[0]\n    df = pd.read_csv(filename, header=0, error_bad_lines=False, sep='\\t')\n    df[\"DATE\"]= pd.to_datetime(df[\"DATE\"]) \n\n    xr = df.set_index(['LATITUDE', 'LONGITUDE', 'DATE', 'easting', 'northing', 'station']).to_xarray()\n\n    # add variable attribute metadata\n    xr['Temp_C'].attrs={'units':'c', 'long_name':'Air Temperature'}\n\n    # Save NetCDF file\n    xr.to_netcdf(output_path + namecsv + '.nc')\n    del namecsv, df, xr"
  },
  {
    "objectID": "posts/data_science/2022-11-11-Scraping_AQI.html",
    "href": "posts/data_science/2022-11-11-Scraping_AQI.html",
    "title": "Scraping AQI",
    "section": "",
    "text": "Data available in https://aqicn.org is good for downloading all data, but this data in compartion of data available in https://aqms.doe.ir/ site is incomplete and incorrect. So, because the latest site has DOE reference it is better to obtain data from this site. Downloading data from https://aqms.doe.ir/ can be done in multi-steps as in following:\n1- Install chrome extension Print Friendly & PDF. 2- Open site in English language. 3- Define Date. 4- Export data as PDF. 5- Convert pdf files to python list with tabula-py python library. 6- Convert list to Pandas Dataframe. 7- This data is AQI and must be converted to Concenteartion, for doing it we can use AQI Calculator."
  },
  {
    "objectID": "posts/explanations/2021-03-01_create_blog.html",
    "href": "posts/explanations/2021-03-01_create_blog.html",
    "title": "Blogging with Quarto",
    "section": "",
    "text": "Building Own weblog with Quarto + Github\n1- Install Quarto in Ubuntu: * Download quarto-1.2.247-linux-amd64.deb fil * run sudo dpkg -i quarto-1.2.247-linux-amd64.deb to instal quarto\n2- Create myblog quarto project in a temperory directory such as temp: -quarto create-project myblog --type website:blog\n3- Created files include: * Created _quarto.yml * Created .gitignore * Created index.qmd * Created posts/welcome/index.qmd * Created posts/post-with-code/index.qmd * Created about.qmd * Created styles.css * Created posts/_metadata.yml\n4- Install Git\nsudo apt-get update & sudo apt-get install git\n5- Install Github Desktop\nwget -qO - https://mirror.mwt.me/ghd/gpgkey | sudo tee /etc/apt/trusted.gpg.d/shiftkey-desktop.asc > /dev/null\nsudo sh -c 'echo \"deb [arch=amd64] https://packagecloud.io/shiftkey/desktop/any/ any main\" > /etc/apt/sources.list.d/packagecloud-shiftkey-desktop.list'\nsudo apt update && sudo apt install github-desktop\nCreate a Github repository Craete a repo with a specific name, such as example name.\n6- Open Github Desktop:\nclone the new github repository created in 5\n4- Change _quarto.yml (in temp directory) and add docs as the output-dir:\nproject:\n  type: website\n  output-dir: docs\n4-1- Copy jupyter note book in a folder inside posts directory For each doc you must have a folder with name of your document. first cell in each jupyter note book as below:\n---\ntitle: \"Geospatial Data Address\"\nauthor: \"Hossein Madadi\"\ndate: \"2021-03-25\"\ncategories: [Geospatial Data]\n---\n5- Go to inside the myblog in temp directory and open terminal 6- Render the site in terminal\n`quarto render`\n7- Copy all files from temp directory to local github repository directory. 8- Commit and push in github desktop 9- In github repository web change settings: in pages from left panel change Branch to main and select docs then save 10- Open weblog with below url:\n`https://username.github.io/reponame`\n11- Quarto render 12- Committing and pushing will make the changes you see locally live on your website \nExample for use .ipynb in Quarto.\nhttps://github.com/fastai/nbdev"
  },
  {
    "objectID": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html",
    "href": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html",
    "title": "Jupyterlab",
    "section": "",
    "text": "Best resources for install Anaconda or Miniconda with spatial packages*\n\nhttps://docs.conda.io/projects/conda/en/latest/user-guide/install/linux.html\nDownload miniconda https://docs.conda.io/en/latest/miniconda.html#linux-installers\nMiniconda3-latest-Linux-x86_64.sh\nTo install Miniconda on Ubuntu 20.04 from command line, it only takes 3 steps excluding creating and activating a conda environment.\n(conda) Constructor to bundle JupyterLab Desktop Server into the stand-alone application. You can install Constructor using: conda install -c conda-forge constructor\nA- Download the latest shell script wget https://repo.anaconda.com/miniconda/Miniconda3-py37_4.8.3-Linux-x86_64.sh\nB- Make the miniconda installation script executable: bash Miniconda3-latest-Linux-x86_64.sh\nC- Run miniconda installation script: ./Miniconda3-py37_4.8.3-Linux-x86_64.sh\n\n\n\nTo create a conda environment, run:\nconda create -n newenv\n\n\n\nconda activate newenv  conda install -c conda-forge jupyterlab\n\n\n\nDownload and Install app:\nhttps://github.com/jupyterlab/jupyterlab-desktop/releases/latest/download/JupyterLab-Setup-Debian.deb\nUse Use the boundled Python environment\n\n\n\nThe geemap package has some optional dependencies, such as “GeoPandas” and “localtileserver”. It is important to install all packages from conda and not using pip for install packages.\nconda create -n gee python  conda install geemap -c conda-forge  conda install -c conda-forge geopandas  conda install -c conda-forge rasterio  … … …\nInstall all packages with conda.\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nError\nModuleNotFoundError                       Traceback (most recent call last)\nCell In [6], line 17\n     15 from sklearn.model_selection import train_test_split\n     16 from sklearn.ensemble import RandomForestClassifier\n---> 17 from treeinterpreter import treeinterpreter as ti\n\nFile ~/Miniconda3/envs/gee/lib/python3.10/site-packages/treeinterpreter/treeinterpreter.py:5\n      2 import numpy as np\n      3 import sklearn\n----> 5 from sklearn.ensemble.forest import ForestClassifier, ForestRegressor\n      6 from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, _tree\n      7 from distutils.version import LooseVersion\n\nModuleNotFoundError: No module named 'sklearn.ensemble.forest'\nSolution\nopen file: File ~/Miniconda3/envs/gee/lib/python3.10/site-packages/treeinterpreter/treeinterpreter.py\nChange from:\nfrom sklearn.ensemble.forest import ForestClassifier, ForestRegressor\nto:\nfrom sklearn.ensemble._forest import ForestClassifier, ForestRegressor\n\n\n\n\n\n\n\n\n\n## NEW EDIT: (2022-09-06)\n\n\nFOR Jupyterlab Desktop\n\n\n-For recent nbclassic and JupyterLab >= 3 use c.ServerApp.root_dir instead of c.NotebookApp.notebook_dir (and jupyter-lab –generate-config instead of jupyter notebook –generate-config).\n\n\n-“jupyter_lab_config.py” file must be created in home/…/.jupyter directory.\n\n\n-Remove the # at the beginning of the line to allow the line to execute\n\n\n-example:\n\n\nc.ServerApp.root_dir = ‘/mnt/…/Anaconda_Projects’\n\n\n-In final: created and modified “jupyter_lab_config.py” file should be moved to /home/…/.config/jupyterlab-desktop\n\n\nFOR Jupyterlab in Browser\n\n\ncreated and modified “jupyter_lab_config.py” file should be moved to /home/…/.jupyter.\n\n\n\nDefault directory for jlab desktop is home, so for change default directory first create configuration file by (Note:Done in newenv environemnt):\njupyter notebook –generate-config\ncreated file: $ /home/…/.jupyter/jupyter_notebook_config.py\nBased on: https://github.com/jupyterlab/jupyterlab-desktop#configuration-files\nBy default JupyterLab Desktop will only load and write to Jupyter configuration located in:\n$XDG_CONFIG_HOME/jupyterlab-desktop or ~/.config/jupyterlab-desktop on Linux\nignoring any other Jupyter configuration which may be present in standard Jupyter paths as defined by jupyter –paths. This includes jupyter-server settings, jupyterlab settings and workspaces, and any other configuration which would normally be shared between Jupyter installations.\nSo, jupyter_notebook_config.py create file should be moved to /home/…/.config/jupyterlab-desktop. Then change from:\n# c.NotebookApp.notebook_dir \nto:\nc.NotebookApp.notebook_dir = 'user/directory/path'"
  },
  {
    "objectID": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#some-problems",
    "href": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#some-problems",
    "title": "Jupyterlab",
    "section": "7- Some Problems",
    "text": "7- Some Problems\nSometimes, we may have a problem such as below:\nCollecting package metadata (current_repodata.json): failed\nUnavailableInvalidChannel: The channel is not accessible or is invalid.\n  channel name: pkgs/main\n  channel url: https://repo.anaconda.com/pkgs/main\n  error code: 403\n\nYou will need to adjust your conda configuration to proceed.\nUse `conda config --show channels` to view your configuration's current state,\nand use `conda config --show-sources` to view config file locations.\nFor solve this problem in terminal of jupyterlab app run:\nconda config --remove-key channels\nThen we can create a virtual environment (venv) by:\nconda create -n <your envn name>\nWith conda info and conda config –show-sources, it can be get some information about jupyterlab app and its venv and etc."
  },
  {
    "objectID": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#jupyterlab-spellchecker",
    "href": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#jupyterlab-spellchecker",
    "title": "Jupyterlab",
    "section": "Jupyterlab spellchecker",
    "text": "Jupyterlab spellchecker\ninstall:\njupyter labextension install @ijmbarr/jupyterlab_spellchecker"
  },
  {
    "objectID": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#uninstall-full-program",
    "href": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#uninstall-full-program",
    "title": "Jupyterlab",
    "section": "Uninstall full program",
    "text": "Uninstall full program\nsudo apt-get purge package-name\nsudo apt-get autoremove"
  },
  {
    "objectID": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#install-fonts",
    "href": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#install-fonts",
    "title": "Jupyterlab",
    "section": "Install fonts",
    "text": "Install fonts\nsudo apt install git\ngit clone https://github.com/fzerorubigd/persian-fonts-linux.git\ncd persian-fonts-linux\n./farsifonts.sh"
  },
  {
    "objectID": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#show-disk-space",
    "href": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#show-disk-space",
    "title": "Jupyterlab",
    "section": "Show disk space",
    "text": "Show disk space\ndf -h"
  },
  {
    "objectID": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#clean-ubuntu",
    "href": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#clean-ubuntu",
    "title": "Jupyterlab",
    "section": "Clean Ubuntu",
    "text": "Clean Ubuntu\nsudo du -sh /var/cache/apt/archives\nsudo apt-get clean\ndf -h"
  },
  {
    "objectID": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#install-packages",
    "href": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#install-packages",
    "title": "Jupyterlab",
    "section": "Install Packages",
    "text": "Install Packages\n\nInstall miniconda\nAnaconda Prompt (miniconda3)[Open miniconda]\nconda update -n base -c defaults conda [Update Conda installed]\nconda install -c anaconda anaconda-navigator [Install Navigator]\nOpen Anaconda Navigator\nOpen terminal\nconda install -c conda-forge gdal [Install GDAL]\nconda install -c anaconda numpy\nconda install -c anaconda pandas\nconda install -c conda-forge geopandas\nconda install -c anaconda xarray\nconda install -c conda-forge matplotlib\nconda install -c conda-forge cartopy\nconda install -c conda-forge descartes [for countries plot in cartopy]\nconda install -c conda-forge shapely\nconda install -c conda-forge fiona\nconda install -c conda-forge pyproj\nconda install -c conda-forge bqplot\nconda install -c conda-forge ipyleaflet\nconda install -c conda-forge nodejs > npm install npm@latest -g [https://nodejs.org/en/]\nconda list"
  },
  {
    "objectID": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#install-packages-in-jupyterlab",
    "href": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#install-packages-in-jupyterlab",
    "title": "Jupyterlab",
    "section": "Install packages in Jupyterlab",
    "text": "Install packages in Jupyterlab\n\njupyter labextension install @jupyter-widgets/jupyterlab-manager jupyter-leaflet\n\n(https://ipyleaflet.readthedocs.io/en/latest/api_reference/basemaps.html)\n-jupyter labextension install @jupyter-widgets/jupyterlab-manager\n-jupyter lab build\n-jupyter nbextension enable –py widgetsnbextension –sys-prefix\n-pip install sidecar\n-jupyter labextension install @jupyter-widgets/jupyterlab-manager\n-jupyter labextension install @jupyter-widgets/jupyterlab-sidecar\n-conda install -c pyviz holoviews bokeh\n\njupyter labextension install @pyviz/jupyterlab_pyviz"
  },
  {
    "objectID": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#install-rasterio",
    "href": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#install-rasterio",
    "title": "Jupyterlab",
    "section": "Install Rasterio",
    "text": "Install Rasterio\nrasterio package must be install with gdal, from ” https://www.lfd.uci.edu/~gohlke/pythonlibs/#gdal ” yuou can find last gdal and rasterio wheel files, then run something like this from the downloads folder:\npip install GDAL-3.1.2-cp39-cp39-win_amd64.whl rasterio-1.1.5-cp39-cp39-win_amd64.whl\nconda install -c conda-forge rasterio > [with python 3.7 (rasterio works with this version) Rasterio 1.0.x works with Python versions 2.7.x and 3.5.0 through 3.7.x, and GDAL versions 1.11.x through 2.4.x. Rasterio 1.0.x is not compatible with GDAL versions 3.0.0 or greater.]\n-with the below command and after failed and failed, installed finally. conda install -c https://conda.anaconda.org/ioos rasterio"
  },
  {
    "objectID": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#cartopy-or-basemap",
    "href": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#cartopy-or-basemap",
    "title": "Jupyterlab",
    "section": "Cartopy or Basemap",
    "text": "Cartopy or Basemap\nBasemap is going away and being replaced with Cartopy in the near future. For this reason, new python learners are recommended to learn Cartopy. So, install cartopy.\nNOTE: DO NOT INSTALL cartopy with basemap, they are conflict."
  },
  {
    "objectID": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#for-update",
    "href": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#for-update",
    "title": "Jupyterlab",
    "section": "For UPDATE",
    "text": "For UPDATE\n\npip uninstall -y setuptools\npip install setuptools\nconda update conda\nconda update -all\nconda update -n base -c defaults conda"
  },
  {
    "objectID": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#run-plotly-in-jupyterlab",
    "href": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#run-plotly-in-jupyterlab",
    "title": "Jupyterlab",
    "section": "Run plotly in jupyterlab",
    "text": "Run plotly in jupyterlab\nFor use in Jupyter lab, you will have to install the plotly jupyterlab extension:\njupyter labextension install jupyterlab-plotly\nOR\njupyter labextension install @jupyterlab/plotly-extension\njupyter labextension list\njupyter lab build\nThen reopen anaconda jupyterlab"
  },
  {
    "objectID": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#persian-fornt",
    "href": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#persian-fornt",
    "title": "Jupyterlab",
    "section": "Persian fornt",
    "text": "Persian fornt\npip install python-bidi\n-lpympl"
  },
  {
    "objectID": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#markdown-formatting",
    "href": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#markdown-formatting",
    "title": "Jupyterlab",
    "section": "Markdown Formatting",
    "text": "Markdown Formatting\nThe five most important concepts to format your code appropriately when using markdown are:\n\nItalics: Surround your text with ‘_’ or ‘*’\nBold: Surround your text with ’__’ or ’**’\ninline: Surround your text with ‘`’\n\nblockquote: Place ‘>’ before your text.\n\nLinks: Surround the text you want to link with ‘[]’ and place the link adjacent to the text, surrounded with ‘()’\n\n\nHeadings\nNotice that including a hashtag before the text in a markdown cell makes the text a heading. The number of hashtags you include will determine the priority of the header (‘#’ is level one, ‘##’ is level two, ‘###’ is level three and ‘####’ is level four).\n# H1\n## H2\n### H3\n#### H4\n##### H5\n###### H6\n\nAlternatively, for H1 and H2, an underline-ish style:\n\nAlt-H1\n======\n\nAlt-H2\n------"
  },
  {
    "objectID": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#h2",
    "href": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#h2",
    "title": "Jupyterlab",
    "section": "H2",
    "text": "H2\n\nH3\n\nH4\n\nH5\n\nH6\nAlternatively, for H1 and H2, an underline-ish style:"
  },
  {
    "objectID": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#alt-h2",
    "href": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#alt-h2",
    "title": "Jupyterlab",
    "section": "Alt-H2",
    "text": "Alt-H2\n\n\nEmphasis\nEmphasis, aka italics, with *asterisks* or _underscores_.\n\nStrong emphasis, aka bold, with **asterisks** or __underscores__.\n\nCombined emphasis with **asterisks and _underscores_**.\n\nStrikethrough uses two tildes. ~~Scratch this.~~\nEmphasis, aka italics, with asterisks or underscores.\nStrong emphasis, aka bold, with asterisks or underscores.\nCombined emphasis with asterisks and underscores.\nStrikethrough uses two tildes. Scratch this.\n\n\nLists\nThere are three types of lists in markdown.\nOrdered list:\n\nStep 1\n\nStep 1B\n\nStep 3\n\nUnordered list\n\nCESM-POP\nCESM-MOM\nCESM-CAM\n\nTask list\n\nLearn Jupyter Notebooks\nWriting\nModes\nOther Considerations\n\nSubmit Paper\n\n\nNOTE:\nDouble click on each to see how they are built!\n\n\\(-b \\pm \\sqrt{b^2 - 4ac} \\over 2a\\) \\(x = a_0 + \\frac{1}{a_1 + \\frac{1}{a_2 + \\frac{1}{a_3 + a_4}}}\\) \\(\\forall x \\in X, \\quad \\exists y \\leq \\epsilon\\)"
  },
  {
    "objectID": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#shortcuts-and-tricks",
    "href": "posts/explanations/2021-06-07-My-Notes-Jupyterlab.html#shortcuts-and-tricks",
    "title": "Jupyterlab",
    "section": "Shortcuts and tricks",
    "text": "Shortcuts and tricks\n\nCommand Mode Shortcuts\nThere are a couple of useful keyboard shortcuts in Command Mode that you can leverage to make Jupyter Notebook faster to use. Remember that to switch back and forth between Command Mode and Edit Mode with Esc and Enter.\nm: Convert cell to Markdown\ny: Convert cell to Code\nD+D: Delete cell\no: Toggle between hide or show output\nShift+Arrow up/Arrow down: Selects multiple cells. Once you have selected them you can operate on them like a batch (run, copy, paste etc).\nShift+M: Merge selected cells.\nShift+Tab: [press once] Tells you which parameters to pass on a function\nShift+Tab: [press three times] Gives additional information on the method"
  },
  {
    "objectID": "posts/explanations/2021-07-02-ML-Resources.html",
    "href": "posts/explanations/2021-07-02-ML-Resources.html",
    "title": "ML-DL Resources",
    "section": "",
    "text": "Machine Learning Algorithms with Python, All Machine Learning Algorithms Explained with Python\nFree courses from Universities\nDust in the Machine\nData Preparation for Machine Learning (7-Day Mini-Course)\nLinear Algebra for Machine Learning (7-Day Mini-Course)\nHow to Calculate Correlation Between Variables in Python\nNeed Help Getting Started with Applied Machine Learning?\nML YouTube Courses\nStatistics and probability\nMachine Learning for Beginners\n\n11- Data Science: Machine Learning\n12- My Advice To Machine Learning Newbies After 3 Years In The Game\n13- So You Want to Do Machine Learning But Don’t Know Where to Start"
  },
  {
    "objectID": "posts/explanations/2022-09-30-My-Notes-Ubuntu.html",
    "href": "posts/explanations/2022-09-30-My-Notes-Ubuntu.html",
    "title": "Ubuntu",
    "section": "",
    "text": "Problem: In terminal I’am seeing “bash: /etc/profile.d/vte.sh: No such file or directory”\nSolution:\nhttps://askubuntu.com/questions/1283991/doubt-in-terminal\nJust look in your /etc/profile.d folder: ls -l /etc/profile.d/vte* to see if there are any files starting with vte. In my case I found two files:\n-rw-r--r-- 1 root root 1368 Jun 11  2020 /etc/profile.d/vte-2.91.sh -rw-r--r-- 1 root root  966 Jun 11  2020 /etc/profile.d/vte.csh\nIf you find the above, then you can just create a link to one of the files:\ncd /etc/profile.d sudo ln -s vte-2.91.sh ./vte.sh"
  },
  {
    "objectID": "posts/explanations/2022-09-30-My-Notes-Ubuntu.html#system-program-problem-detected",
    "href": "posts/explanations/2022-09-30-My-Notes-Ubuntu.html#system-program-problem-detected",
    "title": "Ubuntu",
    "section": "2- System program problem detected?",
    "text": "2- System program problem detected?\nProblem:\nI keep getting, since several days, “System program problem detected” error message\nSolution:\nhttps://askubuntu.com/questions/1160113/system-program-problem-detected\nsudo rm /var/crash/*"
  },
  {
    "objectID": "posts/explanations/2022-09-30-My-Notes-Ubuntu.html#wifi-randomly-disconnected-on-ubuntu",
    "href": "posts/explanations/2022-09-30-My-Notes-Ubuntu.html#wifi-randomly-disconnected-on-ubuntu",
    "title": "Ubuntu",
    "section": "3- WiFi randomly disconnected on Ubuntu",
    "text": "3- WiFi randomly disconnected on Ubuntu\nProblem:\nThe WiFi connection auto disconnected every 5 - 10 minutes but wifi signal is still fine.\nSolution:\nhttps://askubuntu.com/questions/1030653/wifi-randomly-disconnected-on-ubuntu-18-04-lts\nTry disabling wifi power management by opening /etc/NetworkManager/conf.d/default-wifi-powersave-on.conf and changing\nwifi.powersave = 3\nto\nwifi.powersave = 2"
  },
  {
    "objectID": "posts/explanations/2022-09-30-My-Notes-Ubuntu.html#install-vpn-connection-for-university",
    "href": "posts/explanations/2022-09-30-My-Notes-Ubuntu.html#install-vpn-connection-for-university",
    "title": "Ubuntu",
    "section": "4- Install vpn connection for university",
    "text": "4- Install vpn connection for university\nsudo apt-get install network-manager-openvpn-gnome"
  },
  {
    "objectID": "posts/explanations/2022-09-30-My-Notes-Ubuntu.html#wifi-problem-after-install-ubuntu",
    "href": "posts/explanations/2022-09-30-My-Notes-Ubuntu.html#wifi-problem-after-install-ubuntu",
    "title": "Ubuntu",
    "section": "5- Wifi Problem After Install Ubuntu",
    "text": "5- Wifi Problem After Install Ubuntu\n1- After install ubuntu when wifi adaptor not working first with “USB tethering” phone and usb cable connect to internet\n2- https://askubuntu.com/questions/1306507/wifi-stopped-working-rtl8821ce-ubuntu-20-04/1306560#1306560\nthis answer is best solution."
  },
  {
    "objectID": "posts/explanations/2022-09-30-My-Notes-Ubuntu.html#battery-problem-after-install-ubuntu",
    "href": "posts/explanations/2022-09-30-My-Notes-Ubuntu.html#battery-problem-after-install-ubuntu",
    "title": "Ubuntu",
    "section": "6- Battery Problem After Install Ubuntu",
    "text": "6- Battery Problem After Install Ubuntu\n1- After install new version of Ubuntu, Battery percentage shows constant number:\nsolution: Update kernel, for example, after install Ubuntu Budgie 22.10 you must update kernel from 5.9 to 6.0."
  },
  {
    "objectID": "posts/explanations/2022-09-30-My-Notes-Ubuntu.html#jupyter-home",
    "href": "posts/explanations/2022-09-30-My-Notes-Ubuntu.html#jupyter-home",
    "title": "Ubuntu",
    "section": "7- Jupyter home",
    "text": "7- Jupyter home\nconda activate /home/nilik/MYPROGRAMS/miniconda3/envs/envinfo\nBudgie setting reset: nohup budgie-panel –reset –replace &\n\n\n\n\n\n\nReset Budgie from Terminal\n\n\n\n\nnvidia-smi\n\n\nhttps://www.linuxcapable.com/how-to-install-or-upgrade-nvidia-drivers-on-ubuntu-21-10-impish-indri/\n\n\n\nsuspend & wake up problem:\nGRUB_CMDLINE_LINUX_DEFAULT=“quiet scsi_mod.scan=sync”\n\n\n\n\n\n\nChange Keyboard Language\n\n\n\n\nInstall Okular from not flathub beacuse of “open new files in new tabs” works correctly.\n\n\nFor Dark theme in okular: sudo gedit /etc/environmen\n\n\nadd: QT_QPA_PLATFORMTHEME=gtk2\n\n\nthen reboot.\n\n\n\nKeyboard Layout working correctly in persian:\nIBUs Preferences –> Advances –> Keyboard Layout –> use system keyboard layout"
  },
  {
    "objectID": "posts/explanations/2022-09-30-My-Notes-Ubuntu.html#install-java",
    "href": "posts/explanations/2022-09-30-My-Notes-Ubuntu.html#install-java",
    "title": "Ubuntu",
    "section": "8- Install Java",
    "text": "8- Install Java"
  },
  {
    "objectID": "posts/explanations/2022-09-30-My-Notes-Ubuntu.html#libreoffice",
    "href": "posts/explanations/2022-09-30-My-Notes-Ubuntu.html#libreoffice",
    "title": "Ubuntu",
    "section": "9- Libreoffice",
    "text": "9- Libreoffice\nInstall JAVA for using zotero extention in Libreoffice\nsudo apt-get install libreoffice-java-common\nInstall Times New Roman font on Ubuntu:\nsudo apt-get --reinstall install ttf-mscorefonts-installer"
  },
  {
    "objectID": "posts/geospatial/2021-03-25-address_urls_geodatabase.html",
    "href": "posts/geospatial/2021-03-25-address_urls_geodatabase.html",
    "title": "Geospatial Data Address",
    "section": "",
    "text": "Worldclim\nAnnual average climate data\nClimate charts\nGlobal Historical Climatology Network Monthly\nClimate Data Online Search ***\nClimate Scenario Data from the Rossby Centre\nUpperair Air Data\nMerra 2\nCopernicus\nEumetsat\nGlobal Surface Summary of the Day - GSOD ***\nIntegrated Surface Dataset (Global) ***\nNOAA Climate Data\nSurface Data Hourly Global\nNOAA Dataset Search\nIndex of 1 2\nFree access to NCEI’s archive of global coastal, oceanographic, geophysical, climate, and historical weather data ***\nRenewable point data\nESA climate office or\nTemperature and Precipitation data 1, 2, 3\nClimate Data Online: Dataset Discovery"
  },
  {
    "objectID": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#downscaling-merra2-and-other-global-datasets",
    "href": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#downscaling-merra2-and-other-global-datasets",
    "title": "Geospatial Data Address",
    "section": "Downscaling MERRA2 and other Global Datasets",
    "text": "Downscaling MERRA2 and other Global Datasets\n\nThe Land surface Data Toolkit (LDT v7.2) – a data fusion environment for land data assimilation systems 1 2 3\nGlobSim: downscaling global reanalysis /// GlobSim (v1.0): deriving meteorological time series for point locations from multiple global reanalyses 1 2"
  },
  {
    "objectID": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#satellite-data",
    "href": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#satellite-data",
    "title": "Geospatial Data Address",
    "section": "Satellite data",
    "text": "Satellite data\n\nVIIRS Plus DMSP Change in Lights (VIIRS+DMSP dLIGHT), v1 (1992, 2002, 2013)\nEarthexplorer\nSearch Earthdata\nLANCE: NASA Near Real-Time Data and Imagery\nHazards and Disasters\nActive Fire Data\nFire Information for Resource Management System (FIRMS)\nWorldview Earthdata\nWorldview Snapshots\nGlovis\nNasa Earth Observations\nEarthNow! Landsat Image Viewer 1, 2\nSAR Data\n9 Best Free Land Cover/Land Use Data\nTerraScope - Free resource for sentinel satellites data\nAssessment of a Future Copernicus Earth Observation Service Component to Support Sustainable Forest Monitoring\nCopernicus Biomass\nGlobal Forest Watch map 1 2 3\nSPOT satellites (1, 2, 3, 4 and 5 archive)"
  },
  {
    "objectID": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#sentinel-data",
    "href": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#sentinel-data",
    "title": "Geospatial Data Address",
    "section": "Sentinel Data",
    "text": "Sentinel Data\n\nDashboard\nopenEO develops an open API to connect R, Python, JavaScript and other clients to big Earth observation cloud back-ends in a simple and unified way\nSentinell Hub\nSentinel5P\nVito Dataset\nTerraScope - Free resource for sentinel satellites data\nAssessment of a Future Copernicus Earth Observation Service Component to Support Sustainable Forest Monitoring\nCopernicus Biomass\nSea Surface Temperature\nSoil Moisture\nWater Vapour\nAerosol\nFire\nGreenhouse Gases (GHGs)\nHigh Resolution Land Cover\nLand Cover\nLakes\nLand Surface Temperature\nOcean Colour\nOzone\nRECCAP-2 supports and accelerates the analysis of regional carbon budgets\nSea State\nSea Surface Salinity\nGlobal Forest Watch map 1 2 3"
  },
  {
    "objectID": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#terrian",
    "href": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#terrian",
    "title": "Geospatial Data Address",
    "section": "Terrian",
    "text": "Terrian\n\nThe Global Multi-Resolution Topography (GMRT) Synthesis, Bathymetry and Dem\nOpenTopography High-Resolution Topography Data and Tools\nSRTM data\nACE2 (Altimeter Corrected Elevations) DEM is a global DEM at 3” (approx 90m at the equator), 9”, 30’ (approx 1km at the equator) and 5’ resolution\nACE - Altimeter Corrected Elevations\nDSM ALOS Global Digital Surface Model “ALOS World 3D - 30m\nDTM FABDEM\nDSM and DTM can be used in 3D building in QGIS with Mapflow plugin"
  },
  {
    "objectID": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#hydrology",
    "href": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#hydrology",
    "title": "Geospatial Data Address",
    "section": "Hydrology",
    "text": "Hydrology\n\nBasins, Rivers, Drainages and etc."
  },
  {
    "objectID": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#human",
    "href": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#human",
    "title": "Geospatial Data Address",
    "section": "Human",
    "text": "Human\n\nAnthropogenic Biomes 2000\nGlobal 1-km Downscaled Population Base Year and Projection Grids Based on the SSPs, v1.01 (2000 – 2100)\nGlobal Rural-Urban Mapping Project (GRUMP)\nSocioeconomic Data and Applications Center (sedac)"
  },
  {
    "objectID": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#sea",
    "href": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#sea",
    "title": "Geospatial Data Address",
    "section": "Sea",
    "text": "Sea\n\nOpenTopography High-Resolution Topography Data and Tools\nThe PO.DAAC: An Open Ocean of Remote Sensing and In Situ Data for Science in the Cloud\nOcean Dataset\nERDDAP oceanographic data\nFind and download data for your coastal management needs\nDigital Coast to Get the Data, Tools\nNOAA Class\nBathymetry data sets for the world’s oceans"
  },
  {
    "objectID": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#github",
    "href": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#github",
    "title": "Geospatial Data Address",
    "section": "Github",
    "text": "Github\n\nGlobal Map data archives\nDownload MERRA 2 Data 1 2"
  },
  {
    "objectID": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#international-organisations",
    "href": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#international-organisations",
    "title": "Geospatial Data Address",
    "section": "International Organisations",
    "text": "International Organisations\n\nFao Geonetwork\nUNEP Environmental Data Explorer\nIntegrated Population and Environmental Data\nNatural Earthdata, Free vector and raster map data at 1:10m, 1:50m, and 1:110m scales\nGeoportal\nGoogle Dataset Search\nASDC Tools and Services"
  },
  {
    "objectID": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#atmosphere",
    "href": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#atmosphere",
    "title": "Geospatial Data Address",
    "section": "Atmosphere",
    "text": "Atmosphere\n\nAtmospheric Science Data Center\nCopernicus"
  },
  {
    "objectID": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#nasa-data",
    "href": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#nasa-data",
    "title": "Geospatial Data Address",
    "section": "NASA Data",
    "text": "NASA Data\n\nGiovanni\nGES DISC"
  },
  {
    "objectID": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#soil",
    "href": "posts/geospatial/2021-03-25-address_urls_geodatabase.html#soil",
    "title": "Geospatial Data Address",
    "section": "Soil",
    "text": "Soil\n\nGlobal maps for Soil Hydraulic Properties"
  },
  {
    "objectID": "posts/geospatial/2021-07-03-Learning-GIS-RS.html",
    "href": "posts/geospatial/2021-07-03-Learning-GIS-RS.html",
    "title": "GIS & RS learning and notes",
    "section": "",
    "text": "25 Map Types: Brilliant Ideas to Build Unbeatable Maps"
  },
  {
    "objectID": "posts/geospatial/2021-07-03-Learning-GIS-RS.html#rs",
    "href": "posts/geospatial/2021-07-03-Learning-GIS-RS.html#rs",
    "title": "GIS & RS learning and notes",
    "section": "RS",
    "text": "RS\n\nObserving Earth From Space\nORNL DAAC\nEducational resource for exploring satellite images\nE-Learning LP DAAC\nMethane Emissions from Dairy Sources"
  },
  {
    "objectID": "posts/geospatial/2021-07-03-Learning-GIS-RS.html#python",
    "href": "posts/geospatial/2021-07-03-Learning-GIS-RS.html#python",
    "title": "GIS & RS learning and notes",
    "section": "Python",
    "text": "Python\n\nA Python package for geospatial analysis and interactive mapping in a Jupyter environment\nAwesome-EarthObservation-Code 1 2\nDownloading YouTube Videos\nUsing Pandas and Python to Explore Your Dataset\nCreate Beautiful Tkinter GUIs by Drag and Drop\nA simple way of creating movies from xarray objects"
  }
]